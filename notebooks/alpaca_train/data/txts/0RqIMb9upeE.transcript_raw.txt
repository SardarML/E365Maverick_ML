 Welcome everyone to Leveraging Data Integration  for Strategic GIS Governance.  Today, I am joined by both Leslie and Dean.  So Leslie, would you like to give a quick intro to yourself?  Sure, I'm Leslie.  I work for one of SAFe's partners in Canada.  We have been partners with SAFe  for at least 20 years now, I guess.  And we do sort of offer all services around, you know,  FME, FME server, development, coaching, consulting, training.  So we've been working,  and I've been working with Concertech for 18 years  and love FME, obviously, very much.  Yeah, and I'm Dean with SAFe,  and I've, yeah, I actually didn't realize that, Leslie.  I guess I've been with SAFe about the same time  you've been with Concertech.  So that's an interesting coincidence.  And I work with Mark Stokes in the strategic experts team.  And so we do everything from like pilots and prototypes,  sort of for knowledge transfer.  And the other thing that I,  one of my roles is product manager for open standards.  So I do a fair bit of liaison work with groups  like the OGC and over the years with Inspire  and Building Smart and groups like that.  So, yeah.  Awesome, and speaking of Mark Stokes,  Mark will be joining us on the back end for some Q&A.  So if you do have any questions throughout the webinar,  definitely leave those under the questions tab  on the bottom right,  and Mark will be keeping an eye on that.  And then we will also have a live Q&A session at the end.  Chat, you're all using it to let us know  where you're tuning in from.  So keep on doing that, we'd love to see it.  Share your reactions with us during the webinar as well.  There's a button in the middle on the bottom.  And then if you do have any audio issues,  click that button on the bottom left.  There's four simple steps for troubleshooting.  And tip, the first one is usually refreshing your page  if you're having any issues there.  If you would like to download the deck  and follow along with us live,  you can do so by clicking the top right button there.  And as I understand it,  we actually have some bonus slides in there as well.  Is that right, Dean?  That's correct.  Yeah, most of my decks have a bit of bonus in it.  Yeah, so definitely download those as a resource,  and we'll also send those out in the follow-up email.  All right, and at this point,  I'll get our presenters to turn off our webcam  so we can save on some bandwidth for some upcoming demos.  And I'll pass it back to Dean  once we've done that for the agenda.  Yeah, thanks, Elizabeth.  So yeah, this is a quick overview  of what we're gonna cover today.  First of all, we'll give you an intro  to what we're actually talking about  when we're discussing data and GIS governance  and why is this an important topic  or why you should be interested.  Then we'll dive into how FME supports data governance,  what sort of are some of the key capabilities  on the FME platform.  And then we'll look at how FME is used that way.  And then we'll look at a few demos  related to governance from FME,  working with metadata and other types of validation.  And Leslie will go into some real-world examples  after I talk a bit about best practices.  And then we'll look at some trends going forward.  And hopefully we'll have a bit of time there  for Q&A as well.  So why don't we have a quick poll before we dive in  just to get some of your impressions about governance.  So if everyone wants to head down  to that polls tab on the bottom right,  I've launched it there.  We'll give everyone a few moments here to place their votes.  Yeah, and there's a few options.  So take your time to look over those.  And we tried to include an agnostic option  at the bottom there.  If you're not yet convinced that governance  is for you yet.  Okay, it looks like we have the majority voted now.  And it looks like better data management is a key one here.  60% of people would say that's the primary motivation.  Yeah, and then I guess number two  would be improved decision-making.  So ultimately, yeah, why do we need better data  and better data management?  Ultimately that's for the end users of the data.  Yeah.  Awesome, thanks everyone for voting there.  And we do have a few people yet to convince  that governance is important.  So let's see if we can do that.  There we go.  Okay, so in terms of why should we bother with governance?  Some people might consider that governance  is a bit of a dry topic.  You know, it's like, oh, why do we need to do governance?  And, you know, what is, it sounds a little bit bureaucratic.  And, you know, I actually, if you think about it,  while it might not sound that exciting,  there's two aspects here.  First of all, it can save you from a lot of pain  because if you do have bad data,  you know, you can spend a lot of time  trying to clean that up.  And the other thing is good data or good data quality  can actually enable you to do some pretty exciting stuff.  So we'll see a couple of examples in a minute.  And another aspect is that the more data volume,  complexity of data, the more updates you have to do,  the more you need good governance and automation  in order to manage your data.  So at the end of the day,  kind of like some people from the poll,  the decision, the quality of your decisions  are gonna be limited by the quality of your data.  And here's a quote from Matthew Lewin from Esri.  Governance is, you know,  one of the most important factors determining  whether or not your GIS will actually be successful.  So let's just run this demo quick.  So why are we looking at an airport?  In this particular case, it's a digital twin.  And what does this have to do with data governance?  Well, the bottom line here is that this digital twin  would not be possible without good data  and good data governance  because this is not just a pretty picture.  It's actually a lot of built on top of a BIM.  So building information model,  which has a lot of standards itself.  And so it was a very rich data model  where you can click every single object here,  has schedules associated with it for maintenance,  it has all of the different parts  that went into building it.  And to make it a digital twin,  it also has a real time data feeds  telling you what the status  of all these different components are.  And, you know, whether they're working or not  or something needs maintenance,  which can automatically, you know,  generate work orders, that sort of thing.  So yeah, you can go to the next slide.  So yeah, I just wanted to give a sort of  a nice visual example as to why governance is important.  Yeah, and just to continue maybe on that  and maybe give a bit of a definition  because like we usually like to start these presentations  with saying, you know, what do we see by governance?  So we're kind of looking at data governance  and GIS governance overall in general.  So I usually like to say there is room in the sandbox  for all the castles,  but we have to agree on how to share the sand.  So there's all kinds of exciting projects that we can do,  but, you know, it does take some work  to keep those things going  and to make them live over time.  And then I just put two quotes that are from a blog article.  I don't know if the links work in them.  That will be something Elizabeth has to maybe check,  but so that, you know,  so these quotes are from articles from Esri  and stuff like that.  And being data governance is the idea  of managing the availability and the usability of our data  and the security and GIS governance is kind of overall,  like, you know, that includes not just our data,  but also our systems, you know,  even the people that are going to work with it.  So how does it help us?  I like to think of it like from this point of view,  because I'm kind of like Dean,  it's like governance doesn't always sound  like the most exciting idea sometimes,  but when you think about what it allows you to do,  that's what's really exciting.  So how does it help us?  Well, if you want to build something really significant  and, you know, and you want it to, you know,  last over time and in the world now,  that's, you know, a multi-user, multi-systems,  multiple platforms,  and where GIS data is getting kind of like integrated  into other business processes and lines,  this is where governance really comes into play  because this is what really allows us  to really build something significant and exciting.  And these are just some of the benefits  that you get from implementing governance, right?  I think at the end of the day,  customer service improvements,  I think that's an improved decision-making.  I think those ones are really key ones for me  because you can have all the greatest tools in the world,  but if the data is unreliable,  then you're not going to draw useful decisions from it.  And I think that's pretty like pretty much  the baseline of this, right?  This is from Matthew Lewin's article from Esri  on sort of the, you know,  the different domains of governance in GIS.  And we're not really going to speak to all of them today.  Obviously, like there's a few though  that I feel like are interesting highlights  for where FME helps the organization make a play.  And if you include FME more as a platform  in your organization,  then, you know, you can reach new levels  for these specific domains.  So one of them might be like platform, for instance.  We see platform, we see our enterprise GIS being,  you know, talked of as a platform now.  So we used to have software and applications.  Now we have platforms  and they live in an ecosystem with many others.  If we think of FME now more as a platform  and instead of just thinking of it as an ETL tool  or that sort of Swiss Army knife  that I can, you know, create like cool scripts with,  and I really think about it as something  that's going to be integral to my system,  this will allow me to do more.  And then the obvious one is data.  I mean, you know, for data,  FME is obviously comes easily to the forefront.  We have the idea of being able to make sure  our data is good quality.  FME can help us put validation measures into place.  Those validation measures could be  from data coming into systems,  data going out, data across systems.  So the same data that might appear  in different applications or different systems  and making sure they're coherent.  So I think FME plays obviously like a great role there.  And, you know, that kind of ties  into the idea of delivery too,  because delivery in GIS might include  like delivery of our tools, our mapping tools,  delivery of mapping tools integrated  into other applications and other business lines.  It might be delivering, you know, web apps,  field apps, things like that.  But delivery is also delivering data  and, you know, to specific groups  or tiers maybe for compliance.  And this is where we do see a really good role for FME  and making sure that we sort of curate  in a sort of predictable fashion,  how the data is delivered in a consistent way,  in a monitored way.  And then the last one where maybe people don't think  of it too much is workforce for me.  You know, we're kind of in a world now  where your GIS system might outlive a lot of your staff.  I think that, you know, in the last years  we've seen a lot of retirements,  but also seen a lot of people shift around.  And I think that you want to be able to have  that flexibility and that ability  to keep your workforce up to date  on all the changing technologies  and also be able to provide, you know,  fast tools like low code solutions like FME is  so that somebody can come in  and the learning curve is much lower.  Yeah, I like that idea of institutional knowledge  capturing that and formalizing it  so that it's not just a couple of whizzy scripts  that are, you know, black boxes  that are keeping your organization running.  Yeah.  And we have lots of examples of, you know,  old code and things left behind  and then other new people have to come in  and try to figure out, you know,  how are we going to, you know, keep the system going  that, you know, we don't necessarily have,  you know, all the information about.  So this is where I like that a lot too.  Thanks Dean.  In case anybody is not necessarily aware  of all the components of FME  or what makes FME now more  of an enterprise integration platform  rather than, you know, traditionally just a tool  to, you know, convert data between formats, let's say.  You know, when you think of all the tools  that make up the FME platform,  you really see that it's more of an automation tool now,  an integration tool, and not just a transfer of data.  So the main, you know, applications  that make up this platform,  I usually like to categorize them as, you know,  we have FME desktop.  So this is what allows us to build our workflow.  So I usually tell people,  you can build your data processes with FME desktop  and you can run them in the desktop,  execute them, create them, you know, develop them,  and this is where you're really trying to develop  how your data is going to be processed,  manipulated, written, validated, you know,  all the things you might,  depending on what kind of integration workflow  you're dealing with.  And then we sort of have the automation aspect of FME,  and we see that with both FME server and FME cloud.  So FME cloud being the SaaS version  and FME server being the enterprise application.  This graphic, I always like it  because it's evolved so much.  Like in the 18 years, like I've been at Concertech,  this graphic has existed yet it has evolved.  It used to be a graphic showing individual data formats,  like, oh, we support MapInfo and then we support Esri  and then we support, you know, CAD  and then we support different specific formats.  And now it's basically different types of data  and a lot that have a spatial component to them.  And so we kind of actually see the evolution  of spatial data over time in general  and how FME has evolved to kind of keep up  in those like newer spaces that we see data  that has, you know, 3D or a spatial component to it.  So, and we see that the complexity  is just definitely growing with time.  All right, so I'll take over here  and show a couple of demos.  And yeah, just quickly go over this.  I had a quick comment.  Thanks, Leslie, for that FME overview  and kind of setting the stage of how FME relates  to governance and what we mean by governance.  And that, I really liked that format slide too.  And I was just thinking, wow,  like if you think about the whole range of data  that you can access with FME,  that doesn't mean it's automatically  gonna be organized.  So obviously you need a good governance approach  to manage that degree of diversity of data and volume.  So one of the ways that I think is crucial  for data management is to have a handle  on what kind of data you have  and how to manage it as metadata.  Because metadata tells you where your data is,  how up to date it is, what's its intended use,  where does it come from, all that contextual information.  So the goal of this particular demo  is we have a feature service  which provides both data and metadata.  It needs to be updated based on some local metadata updates.  So let's say there's a local tool  where somebody has entered some information  and they need those updates to go onto the feature service.  The obstacle there, metadata,  typically in the ISO metadata  that we're used to working with is fairly complex.  It's a large nested XML document,  a bit difficult to work with  if you're used to flat GIS data.  So the solution is FME provides us  with the XML reader, writer,  and then tools like XML updater  that makes it easy to detect changes  and then make updates as needed.  So the result is feature service has metadata  that is automatically updated  according to these latest updates  and that merge basically happens.  So let me just, this is kind of cool  because it's actually not just a demo.  This particular workflow comes from Caltrans.  So they were kind enough to share.  This was kind of developed by Trent at SAFE  and he worked with them to build this.  And so this is actually being used in a production system.  So basically on the left side here,  we have the metadata,  the original metadata from the feature service  and then the updates and they flow through here  and I'll zoom in a little bit.  Read this a bit easier.  And we'll just pop up a couple of the key transformers.  So here's the change detector,  for changes in these attributes.  And we can drill into the document structure of the XML  using that tree control and look for changes.  And then based on those changes,  we do a number of updates here.  And so these are all of the different XML objects  that we're gonna update and merge in values  that are coming from the update document.  And then ultimately here,  XML updater lets us merge those values  right into the XML structure.  So why are we doing it this way  and not with let's say a flattener and a templater?  The nice thing about if you're going from XML to XML,  it's nice to use the updater  because you don't have to kind of flatten  and rebuild the whole structure.  You can more surgically just insert the values  where you need them to go.  And ultimately it goes through a validator  and then out the text file reader.  So I'll go ahead and run that quick.  And you can see in this particular case,  I'm just pushing through one update.  And then if I go to here,  you can see that this is the feature service data  with that linkage at the bottom.  This is the update,  which has additional information about contact information,  has a mod date, timestamp,  and it has this bounds box.  And then that gets merged into the output.  So here you have a combination of the update dates  and the new contact information,  and also the new B-box,  but it still has some of the old information  from the feature service.  So yeah, not super visual,  but it is a good example  of using FME to automate the metadata updates,  which is pretty crucial for good data governance.  And the next example I'll show you quickly  is metadata harvesting.  And here, again, we wanna do some automation.  And one of the things that people kind of eyes glaze over  a bit when you talk about metadata,  because it can be a pain if you have to go through  and manually enter information.  But in this, FME can be used to automate  harvesting of metadata and then doing updates that way.  So this is actually, I'll jump over to the workspace.  And what this is doing is it's reading from a geodatabase  and grabbing all of the values and parameters  from that data.  Here, I'll just show you what the dataset looks like.  So this is just a Vancouver dataset,  probably from the training data.  And you can see information about community centers,  transit stations, and whatnot.  And so what we wanna do is,  let's say we don't have any metadata  and we just wanna extract the metadata that's there.  And so what this workflow is doing  is it's reading the table names,  it's grabbing the update timestamp, a unique ID,  also auto-generating a category and a list of fields.  So I'm not gonna go through all of that.  You can see here's the bounding box accumulator  and the attribute exploder is what we use  to generate all of the field names.  And everything here, in this case,  gets merged into this XML template for the metadata.  And then that gets validated and written out.  And so if we look at the output for that,  go ahead and run this.  So it's reading all these tables,  but it's only writing out one record per table.  And then it has all the fields coming in as well  for keywords.  And so if we look at the metadata for libraries,  you can see we have a list of field names here  and we also have that dynamic bounds generated  from the data.  And the same thing goes for the community centers,  bounds and keywords and other information.  I think there was a category field too, as well.  So, all right, so back to the deck.  How can FME support your governance framework?  What are some best practices?  This is just sort of a high level snapshot  of a governance plan.  Some of the things that go into a plan  are your governance policy.  I'm not gonna go through everything.  But the key thing is whatever you decide on  for roles and responsibilities  and how you're gonna manage the data lifecycle,  data management lifecycle,  FME can support your ability to implement that  every step of the way.  So here's some aspects of how FME technically  can help you implement your governance.  And from, let's say, the FME Engine perspective,  of course, we know that FME is an ideal tool  to span all the different silos  of different types of data,  different subsystems across your enterprise.  And you can pull data from across those and manage data.  There's also a lot of tools in FME  to help you validate your data  in order to automate updates  and make sure you're not corrupting it.  We have very good support for standards  and I'll have some examples of that in a second.  And yeah, validation, we have a lot of tools  both for geometry and attribute validation.  And at the end of the day,  in order to take all this information  and make it easier to consume,  we support generating reports,  which might be HTML, PDF, or log, automated logging.  And on the server side, you take that engine  and now you have full automation.  And automation is really key for governance  because now you have workflows that are reliable,  repeatable, and you can remove that human error aspect  to it.  And when you have that automation across the enterprise,  so the data fusion across the enterprise,  you can have workflows that span those subsystems.  And we've talked a bit about validation and updates already  and Leslie mentioned data distribution.  So there's many aspects of data governance  that the server platform can support you on,  things like access control security.  And I kind of added notifications.  We'll see an example of that  in some of the customer examples.  So a couple of words on standards  before I show you my last example,  our last demo example,  and that is we really have made standards  a central component or a part of our planning  and a roadmap.  And so recently we had certifications,  got certification for a number of the OGC standards,  the ones that are supported by the test suite  and so for GML, GeoPackage, GeoTIFF, and others.  And we have support for more than 30 OGC standards  and there's more coming with the open API,  OGC features API, for example.  So yeah, I think standards are really crucial  because that's a way in terms of governance  where you can have an external standard  that helps define your internal standards as well.  And that way you can actually take tools  that were developed by third parties  and as long as they're compliant with that standard,  you can deploy them internally.  It just gives you that sort of,  that kind of governance just gives you  that extra scalability.  And for example, one of the benefits,  we are also emphasizing cloud-native,  so cloud-optimized GeoTIFF.  If you implement that standard,  now you have that scalability in the cloud.  And we've already talked about metadata,  but there's a number of standards there.  Stack is an important cloud-native data catalog  that lets you consume cloud-optimized GeoTIFF, for example.  So a couple more words about validation.  Mentioned we cover validation of metadata,  schema, and the data content itself.  And there's just a few transformers  that are really helpful.  Things like Attribute Validator or Geometry Validator  and Tester would probably be the top ones there.  So there's lots of tools there to support data validation,  and we have some really good examples  in on our knowledge base.  And just to wrap up, in terms of my demos,  I'll show you, I just wanted to show you  a quick example of the IMD validator.  So moving beyond metadata to data content,  and this really covers both geometry  and business rules for the attribution.  And so here's an example of the validation report.  And if I just click on this, I can go to the actual report.  You can see that it's got,  GeoFence has an interior ring.  That means there's a donut  when it's just supposed to be a single polygon,  area polygon.  So we're doing both geometry checks.  And if we go further down,  there's lots of data content checks on unique IDs  or missing IDs, valid start times.  And then if we go to the very bottom,  we can actually see a visual representation  of the Victoria Airport.  We can zoom in, click on a specific ID and say,  okay, there's a problem with that particular amenity,  and I can search that ID and go back  to that line in the table and figure out what the error was.  So this is just an example of a validation report  for a very complex standard.  So the IMDF standard, even the format is simple  based on GeoJSON, but the business rule set  is probably one of the most complex ones we've encountered.  And so you really do need automation  if you're gonna comply with that standard.  So that's basically all I was gonna say.  I just wanted to give that example.  I thought the indoor mapping does really relate  to data governance because it shows,  in this particular case, complying with that standard.  And it also links in a bit with Digital Twin,  which was our first example.  And I'll get back to that a little later.  So I'll pass it over to Leslie,  and you're gonna talk about some real world  customer examples where FME is used to support governance.  Yep, so the first use case I wanna talk about  is actually a tool that we built for multiple clients  in Quebec for the management of their cadastral data.  So it's just an example of where you really have to think  about the idea that the data is always changing  in the management of this,  and their cities are basically constantly receiving  new cadastral updates that they have to integrate  into their parcel fabric.  And then they actually have to publish the data back out  to a different provincial ministry  and in a very, very specific open format in a GML format  with a very specific and strict schema.  So this is an ongoing need.  So it's not like maybe a long time ago,  you might make a map and then spend weeks and weeks  and weeks, and then you have the perfect map.  It is now the published map.  This is living data and it has to constantly be updated,  but you have to maintain its quality  and maintaining its quality means being able to adhere  to the different standards you need,  making sure that the data is coherent  so that it can then be used in other business processes.  So the data that always gets received  is in a very specific format in a DXF format.  And so it does not match the internal format  that organizations use to manage their cadastral data.  So they need to be able to manage their own data  in their own format for their business needs  to integrate with all their other systems and applications.  So it's their governed cadastral fabric,  but then they have to be able to constantly bring in data  from the outside and constantly push data back out  in these other formats.  So by looking at the governance of this system,  you have to be able to think this is not static  and it's constantly gonna change.  So I have to be able to have tools  that let me convert the data,  have tools that let me validate that it's correct.  I need to be able to maintain and use the data  in my own format, in my own system.  And then I need to also be able to constantly be able to,  at any moment, produce a set in this external format.  So the tools that we did are mostly FME-based  and so they automatically take in those external DXF files,  but we have to do validation  because even though there's a very strict standard  on how the data is supposed to be formatted,  it is not always perfect.  It's a very specific format,  kind of like a distributed GIS.  So it's basically CAD files,  but you can reconstruct GIS data from those CAD files.  And so in the processes,  we're actually having to validate  to make sure that it's structurally coherent  to be able to then import the tool  into the current parcel fabric.  So then we import the data into the database at the end,  and then that allows them to do their business with it,  integrate that parcel data with other applications  and systems and serve their business processes.  And then we also use FME at the end of that  to extract the data to the very specific GML format  with a very specific schema that really doesn't match  with a city needs for its business needs, right?  But that is a great open format for the province  because they're trying to get data  from many municipalities across the whole province.  So they need something that's standardized  so that they can integrate for their needs and their system.  So they chose an open standard  to be able to have a sort of neutral platform  with a certain standard.  So we need to be able to adhere to that standard.  So even on the export,  there has to be validation that the FME workspace is doing  to make sure the data coherently meets that standard.  So that's where I feel like in that idea  of like sort of like data intake and validation,  there are some other examples I have from clients.  We have newer and newer ways, like there's LIDAR data now,  there's all kinds of data that comes in  or that we might hire outside firms to collect for us.  And usually we end up with only a very specific window  of time to accept that data.  And so we need to be able to have ways  to be able to respond in a timely fashion  so that we can make sure the data is good  and fit for purpose, basically.  This is another example.  This is the city of Sudbury  and they were asked by the auditor  to put in a system to allow them  to monitor road patrol activities  and to provide a solid databases for residents claims.  So one of the needs was that they would get resident claims  and they wouldn't have the data  or the information available to them to be able to verify  or validate or get a clear picture of the circumstances  from a data perspective.  One of the obstacles of this is,  a lot of these kinds of systems sound pretty straightforward.  Okay, the guys who are doing the public roads maintenance,  they're gonna collect the data,  but different people need it for different purposes.  So they may need it to do their own management  and their own dashboards,  but then the risk management people,  they need to be able to extract that information  for resident claims.  And so they need the information in a consistent manner  and if you're gonna use this data  in potentially litigation cases and stuff like that,  you need to be able to have an idea  of the whole lineage of the data, right?  How is it collected?  Where was it collected?  How was the data extracted from the system  in a consistent fashion?  If you have a person trying to do the data extraction,  maybe it won't be done the same way every time.  Maybe some of the data will be missing.  Are we pointing to the right data?  Even if we're running FME desktop,  are we running the right workspace?  So this is where when you have FME as a platform  and you have your GIS governance in place  and you have your enterprise GIS in place,  you can put in governance around that  so you know how the data is being curated.  And one of the nice things about using like FME server  and these kinds of integrations  is you also not only have FME workspaces  that sort of curate how the data is extracted  and how it's provided, how it's validated,  but you also get that sort of traceability  of when was it run?  When was the data extracted?  What did it connect to?  You sort of have a full like lineage of that data  at the end, which becomes important  if you're gonna find yourself using that data  for official activities and stuff like that.  So this is just another graphic  showing what they actually did.  So their actual solution,  because they had multiple audiences,  they had looked at buying specific tools for this,  but realized they had FME as a platform,  they had an enterprise GIS  and they had the tools they needed  to be able to put something in place in house,  something that's flexible and that was able to adapt  as they kind of brought actually these different groups  into also a change management.  Like when you look at the human side of it,  you're asking new people in the field to collect data  where they weren't doing that before.  You're asking their managers to work with  dashboards and information.  They've never done this before.  So FME, because it's so flexible,  it allowed them to phase the project as well.  And definitely that helped with the change management.  So for them, phase one was they deployed quick capture  in order to capture the GIS,  the information in the field,  as to what they were doing for road patrol.  But then the phase two, they developed an FME workspace  that would automatically compile all the deficiencies  that were found and then email a report to the managers.  And this was a transitory phase to help them get used  to the idea of the changes they were dealing with  in terms of like, okay, now you have  all this new information that you didn't have before.  What do you need?  How are you interacting with it?  And stuff like that.  Then after that, they made a switch.  And this is where FME is so great  because it allows them to like re-adapt  as they can sort of improve the business processes.  They created a dashboard for the managers  to see what was going on.  But now we shift FME's role into producing the data  to meet those dashboard needs.  So FME made a shift in terms of what its purpose was there.  And these are easy to do because it's, you know,  a light tool in terms of development.  You're able to basically, you know,  it's a low code solution.  You're able to fit it where it needs to go.  Phase four, they use, so for those people  that actually need that report,  okay, hey, there was an incident,  a resident needs information or something like that.  So the risk management people are able to use  an ArcGIS survey one, two, three form,  and they make a request.  And on the backend, this is where FME's automation is.  FME automatically, you know, through the webhook technology  and FME server is able to run a workspace  that retrieves the required information.  And this is where the governance comes into place.  We have a repeatable pattern that we can trace.  We know where the data is coming from  and emails them the report back to the requester.  And at the end of this,  they added even more in automation into the workflow.  And FME is playing a role you see at multiple places  in order to serve the data out to the different works,  to the different players or stakeholders in this.  So basically they have automation  of the creation of the work orders in CityWorks.  So now they can create, you know, a case and quick capture.  And then FME is vetting the type of case  and creating the type,  proper type of work order  for their work order management system.  So you can see that there's a number of stakeholders  that need the same information, but in different ways.  And by, you know, bringing that FME platform in,  they're able to sort of make sure  that they know where the data is coming from,  how it's being processed, when it's being processed,  and in a timely manner.  So that I found was a fun one.  And then the last one,  I don't have a cool graphical slide for,  but this is just one that we see  for those who might be interested in this sort of thing.  Like the idea of like being able to do data validation  to comply to standards is really important.  So Dean talked a lot about standards, right?  Some standards are more like the formatting of data.  Some standards are very specific data standards.  So above, you know, schema and, you know,  rules in terms of how the data needs  to be provided and produced.  So like, for instance, you know,  as a lot of cities in North America  are moving to like Next Gen 911,  NENA, the organization that manages the GIS standard,  has created a new standard to meet the needs  of the Next Gen 911 environment.  So one of the particularities of Next Gen 911  is that the spatial data will play an integral role  in how calls are routed.  And because of that, you know,  it is gonna be important that, you know,  the GIS data is clean and good.  And one of the obstacles that a lot of organizations  that have to do the aggregation of 911 data phase  is the idea that the address data is constantly changing.  So we're dealing with address data,  we're dealing with boundaries,  boundaries of like police zones, city boundaries,  you know, the 911 dispatch boundaries and stuff like that.  And now, you know, if you can think like, you know,  a lot of us are GIS people in the room,  what are the challenges we might face?  So we're constantly bringing in new roads  or editing the roads data, right?  Think about every like road construction,  create new deviations off road paths and things like that.  So they're constantly having to remerge  multiple jurisdictions of data, you know,  and that can mean quite volumes of data  and there's always changes.  And if you follow the Next Gen 911 standards and rules,  you see that actually, you know, in the future,  the idea is that addresses have to be, you know,  updated in the system within 72 hours.  So, you know, that also kind of like the timeliness  brings its own challenges as well.  So we have worked with different clients,  one in particular to help automate these validations.  So this is part of larger systems.  Again, FME in, you know, as a platform.  So we're talking about FME server automated  in order to be able to take that new,  that take that data and be able to validate it against,  you know, possibly in some cases,  hundreds of rules, literally.  And those rules span from schema rules  are the required attributes filled out.  The spans to geometry rules  are the geometry structurally sound,  but also topological rules,  especially around the boundaries,  which play an important role in this.  So I did wanna be able to say like, you know,  FME when we're trying to comply to standards  and meet needs for fit for purpose  for very specific data purposes, you know,  we do see a lot of use cases here.  Dean.  All right.  Thanks, Leslie.  Yeah, some great examples from Quebec Sudbury  and NextGen 911.  And so I'm gonna talk briefly.  I know we're winding down on time here,  so I'll keep it pretty short about another example.  So NextGen 911 is an example  of a sort of a cross jurisdictional standard.  So the NextGen 911 applies to all of North America,  you know, at different stages or at different rates.  And the European Environment Agency  has to manage data right across all of Europe,  so 33 countries.  And there's a standard there called Inspire  that kind of is behind all this.  And so they have to ingest data from all across Europe,  from, and every country  has got sort of their own different language,  their different internal standards.  And so they've come up with the Inspire standard  that allow people to aggregate data,  but they still get,  so there's different levels of implementation of Inspire.  And so they have to still accept legacy data  in the form of Excel and shape files,  CSV files, as well as things like Inspire Gmail.  So this is obviously a very complex system  and they're running something  like 16 FME servers continuously.  And they have all these automated workflows using FME.  So if you think about a governance challenge,  managing all of the EU's data  is obviously a pretty huge challenge.  And so, yeah, it's another snapshot of the problem  and get regular updates basically in every day,  if not every hour from all these member states  and then validate that and then extract the data from that  and bring it into their system.  So yeah, something like 11,000 jobs a day.  And this is a European Environment Agency  working with SWACO.  So there's lots of,  there's some great webinars on this if you're interested.  Another, I guess this is now going international.  So the Red Cross has a mandate  to support humanitarian aid right around the world.  Everything from things like promoting health,  things you're responding to the pandemic  to say the latest disaster in Turkey and Syria.  And so they have to monitor data on a global basis.  They have automated web feeds that do web scraping.  And then they have a number of data products,  both in terms of a dashboard  at the administrative sort of management level.  So they can see where hotspots are  and where they may need to respond  as well as building data packages  that can be used offline.  Things like a PDF and whatnot  that where there's low connectivity.  And so that's obviously a huge data management challenge.  And this is just a snapshot of one part of it is,  if they're gonna conflate data,  again, from different countries  and they have to respond, let's say to a disaster,  something like the earthquake where you have data,  they have to conflate across international borders.  Obviously, they need some automated tools  that help them make the data more consistent.  And the other thing that's always a challenge  is how do you manage a system,  the kind of, Leslie mentioned earlier,  sort of this whole ecosystem idea  where you have very complex architectures  with parts of your system might be CardoDB,  the other parts are from Esri or Microsoft  and maybe some open source components, PostGIS.  So FME helps you to manage that whole architecture  and you can actually move data where you need it to go,  manage it and report on it.  So a good example of that is Powerlink.  So this is, again, on the sort of emergency management side  for a large utility in Eastern Australia, Queensland.  And so their challenge is they have to monitor  their whole system and anticipate impacts  coming from large, let's say extreme weather events,  storms, floods, fires, that sort of thing.  And then when they anticipate problems,  they have to send out notifications to emergency managers  so that they can position resources to respond as needed.  And so these are some of the products that they generate.  This is all actually done with FME.  And so most of these are PDF maps  showing things like storm tracks.  And the other main aspect of this  is the notification system.  So they have notifications that go out  where they, as they understand more about the storm track  or if there's a fire, what areas are under threat,  they generate notifications that go to  the different utility service and managers there  so that they can respond.  And the other aspect of notifications  from a governance perspective,  which is really important here,  is they actually have statistics and reports  that they generate periodically  showing the uptime of the system  and anytime there's any issues.  So in terms of governance,  they have certain standards that they require  in terms of minimal downtime  and the length of time it takes to generate notifications.  So they have sort of this dashboard  or overview reporting structure there  that shows how many jobs are run  and how responsive the system is.  So as we sort of move towards wrapping up,  just briefly discuss, okay,  how might your work be impacted if, you know,  so we'll talk a little bit about some sort of trends  and key takeaways.  And this is just something to think about  in terms of if you don't implement best practices,  if you don't implement good governance,  what are some, you know, just keep in mind  what the risks to that might be.  And, you know, yeah, go ahead, Leslie.  Yeah, I was just gonna say,  yeah, I wrote Leslie's best practices.  I just wanted to think about, like,  things that I think are important to consider  when you're, like, how is FME gonna play a role  in my broader governance?  And one of them is understanding the different roles  the platform plays.  Like, I think it's good to have a tactical kind of view  of where FME plays the best.  You know, is it gonna be, you know,  where are its best use cases in your organization,  in your GIS, in your needs?  Implement with purpose.  I think that, I mean, I have been implementing FME server  since it first began.  So it's been many years.  And I think that at first people would be like,  oh, we have desktop.  Oh, we're gonna get FME server  and we're gonna do some stuff on it.  And when they didn't implement with purpose,  like not with like a strategy or a tactical approach,  at least, you know, then we ended up with like  many workspaces and some of them,  nobody knew what they do.  And many times I have sat down with somebody  and actually gone through all of their content  and, you know, tried to figure out  what was good and not good.  And so that's definitely like implement with purpose  is something that we do actively with clients now,  because the idea is that it always starts small  when it's small and you have one workspace on FME server,  it's very easy to govern and manage.  And when you have, you know, three, four, 500,  you need purpose.  And integrate FME into all facets of GIS governance.  So again, like, you know,  it does play a role in your technical strategies.  It does play a role in your financial strategies.  It does play a role in your workforce strategies,  especially, and I like the continual improvement mindset.  You know, how can, so it's not static.  We make a plan, but we have a actual purposeful approach  to adapting that plan and helping the platform evolve.  Yeah, I like that last point, Leslie,  because this might be a bit intimidating  for someone who's new to this whole concept  of data governance.  And I think rather than sort of like,  oh, pass fail or all or nothing,  the continual improvement is you can always start somewhere.  If you start, you know, cataloging your data  or validating it, you know,  anything is better than just kind of driving blind.  So we probably have to wrap up in the next two minutes.  We'll just, I just wanted to jump through this really quick  and these slides are available afterwards,  but I just wanted to emphasize in terms of trends,  what good governance enables.  Certainly it enables efficiency  through things like automation, better collaboration.  So if you're using things like open standards,  it's easier to share data, return on investment.  So ultimately your level of maintenance  or struggling with bad data should go down.  And so your system should be more efficient  and we haven't talked too much about it,  but in terms of risk management,  I guess, Leslie, you had a good example from Sudbury,  you know, with the data lineage.  If you've got good governance,  then that actually protects you  as well as things like from hacking or security.  And the last one I'm just gonna briefly highlight here  before we wrap up is innovation.  So there's a lot of innovation  that really depends on good quality data.  Things like BIM, digital twins,  and what we don't really have time to get into  are things like artificial intelligence  would be another example.  So here, I'm not gonna go through these in much detail,  but just to show you some examples  of digital twins at airports,  we have a number of customers of ours  using FME to support building,  first of all, building their BIM  and then making them essentially,  bringing them to life with real-time data.  And they've got this digital twin  that allows them to manage the life of the airport.  And the same thing here at Chipotle,  where they're using the IFC standard,  essentially an enterprise service bus  that lets them, if a runway light goes out,  there's a message that goes through that service bus  and generates a work order.  So there's presentations on this.  And then once you have that infrastructure,  you can do fun things like build apps,  custom apps that allow people  to get to where they need to go  or find the services, the shopping that they need.  So just in terms of lessons learned,  last minute or two here,  yeah, automation basically powers your data flow,  things like using standards like BIM,  supports collaboration.  So indoor mapping, now you can use a lot of different apps  and your data shows up in Apple Maps or Google Maps  if you support the appropriate standard.  ROI, and I think I've kind of covered most of these here.  And then Leslie, you talked about things  like staff turnover and institutional knowledge.  So I think it protects the organization.  So yeah, just the key takeaways here.  There's this concept of if you do base internal standards  like San Francisco with the ACI airport standard,  by basing their internal standards on that,  it allows them to better comply  with external standards as well.  And then ultimately it's the bottom line there.  FME helps you implement your governance policies  by giving you control over your data management.  So whatever that policy might be  in terms of managing the lifecycle,  access control, authorship, lineage,  FME gives you the tools you need to implement that.  Yeah, I think that's,  did you have anything to add there, Leslie?  No, I think you wrapped it up pretty well.  And it's kind of like based on the previous discussions  we were having the last few days.  So I'm pretty happy.  Yeah, there's a bunch of resources there,  again, available in the deck if you download it.  And there's everything from working with metadata.  There's a great blog there,  I think, and presentations as well.  I think presentations by Leslie at past FME events  and some webinars.  So yeah, feel free to dig in and don't be a stranger.  I don't know, Elizabeth,  did you have anything to add to wrap up?  Yeah, so we do have a community badge code this morning.  I'll drop that in the chat.  If you aren't a part of the community,  it's a great place to connect with other users  and a lot of great resources there.  And early bird registration is open  for the peak of data integration as well.  So definitely check that out.  I'll drop the link for that shortly  if you haven't registered yet.  That's in Europe this year.  And with that, we might take a quick glance at the Q&A,  but it does look like we've answered most questions.  There was a question about how is the XML used?  And there were two XML examples.  I wasn't sure which one, but the first one,  the XML data is basically,  I think it's probably a feature service writer  that updates the metadata there afterwards  in a separate workflow.  And yeah.  But yeah, somebody was asking about the workspaces.  So Elizabeth, we'll send out an update, I suppose,  which will have the complete examples attached.  Yeah.  And now Dean, are we thinking that's gonna include  this specific workspace that's up on the screen here?  No, I think that's a survey one, two, three.  So that would probably be Leslie's example.  Yeah.  I mean, it's a corporate example.  I'd have to see if I'd be allowed to,  if they would be willing to share it.  It's actually not that difficult to do,  to use the webhooks.  It's actually a few like clicks,  very low to no code at all.  I've given workshops on it for Eurysa  at the space show last year  on how to webhook survey one, two, three.  You might be able to actually  look at that stuff up there actually.  There was a question right at the top  that we didn't answer yet from Grafton Tech  about, you know, in your opinion,  what are some of the key drivers  for organizations to pursue good governance?  And I know that there's the governing organization.  So sometimes there are legal requirements  like Next Gen 911 or the EU-inspired legislation.  So that kind of almost forces you  to pursue good governance.  But the flip side is, you know,  might just simply be profitability.  If you, you know, you don't wanna waste money,  you don't wanna waste your data resources.  So it might be your shareholders  want you to have good governance,  or you don't want the liability of, you know,  somebody hacking your data.  So you need, you know, good governance on security.  So there's quite a few,  but that's, you know, it's a very good question.  And you have to think yourself about  that's part of what that slide about what happens  if you don't do data governance, what's your risk?  And, you know, data is a very valuable resource.  You do have to manage it well and be intentional.  And Leslie, you were talking about with purpose,  you have to be intentional and you can't do everything.  So maybe that's one of the challenges is,  okay, how do you prioritize?  I don't know, Leslie, if you think about that,  if you were starting with a blank slate,  what do you prioritize for governance?  Yeah, I think, well, I mean,  I think I like the idea of a sort of like  having that traceability.  I mean, I think like, you know,  a lot of people don't talk about metadata a lot,  but I think like knowing where your data came from  is like probably a good start,  like cataloging inventorying, just to have an inventory.  I think, you know, and there are some,  it doesn't have to be the best inventory.  I think you need to start with something.  I think that one of the drivers for governance too,  is the idea that like before we would make a map  and we would highly curate the data,  like a GIS professional would sit behind their desk  and analyze the data and make sure it's good,  make sure it's good, make sure it's good.  And then finally deliver the data.  Now these things are integrated live into other systems.  So I think that that actually, that automation aspect,  that ability to deliver data pretty immediately  for decision-making, I think honestly,  that's been a big driver too.  Yeah, and like you're saying, the metadata is key  and nobody wants to sit there and fill out metadata forms.  So that update has to be automated.  It has to be part of the data update  is the metadata update.  And now you know, well, is this current data  or is it 10 years old?  And if you're driving in an ambulance,  you don't wanna go down a street and figure out that,  well, there's no more bridge there anymore  or something's missing or something's blocking it.  Yeah, so it has to be up to date.  In terms of metadata, we did put out a webinar  roughly a year ago.  So you're welcome to check that one out.  And there's a number of data examples  and workspaces attached to that.  I'll drop that in the chat as well.  Certainly come out to the, if you're based in Europe,  come on out and see us.  Yeah.  I guess it's in, is it in Bonn or Berlin?  Bonn.  Yeah, yeah.  Awesome, yeah, and if you do have a moment  to fill out our webinar survey, we really appreciate it.  It lets us continually improve upon the program  with any feedback there.  It's just a few multiple choice questions.  And with that, a huge thank you to our presenters today,  Dean and Leslie.  Thanks for joining me on this webinar  and all your work creating this content.  We really appreciate it.  And a big thank you to our whole audience  for joining us today.  Thanks everyone.  And hope you have a great rest of your day.  Thanks everyone for your time.  And thanks Leslie for all your great examples and insights.  Thanks guys.  All right.  Thanks everyone.  Bye for now.  Bye, have a good day. 