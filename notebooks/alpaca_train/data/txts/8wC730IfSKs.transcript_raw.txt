 You're listening to Numerically Speaking, the Anaconda podcast.  On this podcast, we'll dive into a variety of topics around data, quantitative computing,  and business and entrepreneurship.  We'll speak to creators of cutting edge open source tools and look at their impact  on research in every domain.  We're excited to bring you insights about data, science, and the people that make it  all happen.  Whether you want to learn about AI or grow your data science career, or just better understand  the numbers and the computers that shape our world, Numerically Speaking is the podcast  for you.  Make sure to subscribe.  For more resources, please visit anaconda.com.  I'm your host, Peter Wayne.  This episode is brought to you by Anaconda Notebooks.  With nothing to install and nothing to configure, Anaconda Notebooks is a lightweight, ready-to-code,  and fully loaded data science environment entirely in your browser.  Spin up new projects with the click of a button, with all the packages and files you  need in one place.  With fast and persistent cloud storage no matter what, wherever you go, your code goes.  And students, listen up.  You also get on-demand access to Anaconda's data science experts.  No matter your experience level, learn through hands-on experimentation, and you'll be predicting  the future with machine learning models in no time.  So what are you waiting for?  Start coding with Anaconda entirely in the cloud on anaconda.cloud.  All right, welcome, welcome.  And I'm really, really excited to invite Ryan here on Numerically Speaking.  Really excited to have this conversation.  I think we have a lot of really fun things to talk about.  And Ryan, you've done some really exciting work.  We talk about so many different things.  But before we do that, would you like to go ahead and give a bit of an introduction about  kind of your background and what you work on, and kind of what brought you into this  whole PyData and cloud and all these different kinds of things?  Sure, yeah.  Really happy to be here.  Thanks for the invitation, Peter.  In terms of my background, I realized that I'm kind of a lifelong hacker and computer  nerd.  I've kind of embraced this identity.  So my father worked for IBM.  We had PCs since as long as I can remember.  Back in the 80s, when I was a little kid, I started coding basic and got a little bit  away from that as I got older.  But then really rediscovered my sort of passion for computing and technology in college.  I got really into the whole sort of streaming media and video and audio thing.  This was back in like 2002, 2003.  So I was like really into like college radio.  I set up like the streaming system for my college radio station.  After that, I worked for a while like at this radio and TV program called Democracy Now  doing like sort of video, audio production stuff in this like sort of indie media like  world.  It feels like a long time ago now.  And then I took a big pivot and I decided to go back to school to do a PhD in climate  science at MIT.  And then I just became, you know, like a scientist.  And I did research studying the oceans, their role in climate.  I've been working as a professor at Columbia since 2013 and, you know, continuing that  research trajectory and working with some great students and postdocs.  But during this past, you know, nine years, I've slowly that this sort of hacker side  of me has slowly been reemerging and in fact sort of taking back over my life and career.  And now I'm at the point where I'm thinking about data and coding and cloud and all of  this stuff, you know, almost all day.  So it's been a fun journey and I feel like it's actually just getting started.  So that's really, yeah, this is, you know, I actually, I didn't know that part of the  streaming media thing.  Did you pay your annual like whatever, 600 bucks to ASCAP or something to be able to  stream radio back then?  Wasn't there something like that?  Because a buddy of mine ran an internet streaming station back then as well.  And I just remember it was like outrageous, well not outrageous, but like there was all  this stuff you had to go through like it was a real radio station.  It was kind of the Wild West for college radio, you know, like we were paying already  licensing fees.  That's how all radio stations were doing it.  But then we just started doing the streaming without, we didn't ask permission really.  And probably after I left, they had to sort that out and actually do it right.  We were mostly like, you know, what is all this tech?  We're setting up servers under the studio, you know, console and learning all about,  you know, compression and protocols.  And it's really interesting how that's actually helped my science a lot.  Because I felt like I had this really solid foundation in like what is digital data?  Like how do we move it around?  Like what is throughput?  Like what is bandwidth?  Like just concepts I kind of took for granted that have been really helpful in computational  science.  I got my start thinking about audio and video actually.  Well, that's interesting that you started there and you did the computer stuff because  you had to.  It was a means to an end, right?  Then you went to go and study climate science and then you found yourself doing more computer  stuff as a means to an end.  And then getting sucked in more and more into that.  So now we, you know, Anaconda and some of the open source folks here at Anaconda have  been working with you and with the Pangeo project for a number of years now.  And there are a lot of really, really fun things that we've built that we've worked  on.  A lot of the open source tools that we built were, many of them had features and things  that came out of needs that you all had in the climate science arena.  It's just a really, really, I think, productive collaboration between the scientific needs  that you all have.  And then of course, also to be clear, you were trying to do a research collaboration  in the cloud.  It was like cloud native science almost, right?  How do we do that?  And of course there's all sorts of sharp rocks to trip on and fall over in doing all  that stuff.  Not all of which are technical, some are organizational.  We'll talk about that later, right?  But then that definitely helped drive and inspire some of the work that we've done  on like FS spec and intake and desk and all these kinds of things.  So I really appreciate your leaning into that collaboration and people who are using those  tools should know they're benefiting from input of your group and from you personally,  of course.  But as you look out right now as the state of science, like just climate science, right?  Tell me about what's top of mind for you in that area as you're thinking about that.  Absolutely.  Well, let me start with something that's really, I think, exciting and inspirational that's  happening right now in climate science.  And I'm involved in some of this at the periphery, but the only way we have really solid information  about what's going to happen to our future climate is through something we call climate  models.  And these are some of the sort of main workhorse applications of traditional high performance  computing, you know, supercomputers, right?  Like that's one of like them, like going back to von Neumann, like this is like why they  built supercomputers to predict the weather and really to project forward the climate.  And these are like, for the most part, like really heavy duty scientific computing applications,  mostly written in Fortran, maintained by these teams at national labs, places like, you know,  you know, the DOE labs and, you know, GFDL at Geophysical Fluid Dynamics Lab and National  Center for Atmospheric Research, you know, beasts of code with a long legacy, very sophisticated  at what they do, very in a way isolated from the rest of computational science, particularly  like modern data science.  And what we're trying to do now is we're trying to fuse those models and enhance them using  stuff from AI, right?  Like we're trying to, basically, these are big PDE solvers, and they don't really incorporate  data directly.  Yet there is all this data out there about the earth that we can potentially leverage  to make the models better.  And so the scientific challenge is how do we actually plug those things together?  How do we actually make a 40-year-old legacy Fortran code, like have a neural network,  you know, from PyTorch running inside it?  And how do we scientifically, what is the right framework to integrate data into that  type of application?  This is ultimately not just a technical problem, but really a interdisciplinary science problem.  So we have this great new collaboration, a couple of projects I'm involved in, one called  Multiscale Machine Learning for Earth System Modeling, and another called Learning the  Earth with Artificial Intelligence and Physics.  That's a new center here at Columbia.  And really, this is about bringing AI scientists, people who are doing, you know, innovating  on machine learning methods together with domain scientists, and figuring out where's  that point where we can plug AI into the climate model and really enhance its predictive capabilities.  So the challenge, I mean, well, so I don't want to rattle on this part too much right  now, but it does seem to me like, yes, absolutely.  And using AI, you know, we talk about AI as if it's this new thing.  But when you zoom out and you look at the cybernetics, and I sort of talked about this  with Paco Nathan in a previous episode, right, that the origin of computing was in prediction.  The origin of computing was in simulation.  We didn't do it to go and do mass telephony.  We didn't do it to go and do banking system reconciliation.  We didn't do it to make computer games and, you know, World of Warcraft.  We did it to predict.  We started, the whole field started in prediction and trying to make guns hit airplanes or make  guns, you know, lob shells onto target, you know, from the rolling sea.  And then that became more and more about simulating things, simulating things.  And then we got these big computers.  And there's this whole like very big iron serious, let's say a branch of the family  tree of computing that actually stayed in that world a bit.  And then it ended up with things like APL and Fortran.  And then for Fortran, we get the influences on things like MATLAB and NumPy, of course.  But the rest of the personal computing world went down a whole different path.  And now we're faced with, at a civilizational level, needing to really, really, really do  like no kidding simulation that we want to see what's going to happen to like billions  of people.  Right.  And in doing all of that, we sort of rediscover AI, right?  The AI winter's over, it's back again.  But now what we found is not only have people lost, well, there's lack of faith in institutions,  there's a lack of trust in science.  Now we're going to put AI into it to then make even more policy, you know, facing kinds  of predictions.  And this is going to sound like, well, you're just bringing Skynet in to tell me what to  do versus no, this is what we built.  Like it was all about prediction from in the first place.  But anyway, not that you're ever going to make that point to, I think, the layperson,  but I do think it's very interesting in this area in particular, we have to get quite serious.  This is not some dolly art thing.  This is like something very serious about understanding what is the AI or what are the  machine learning models training on?  What is in the models?  What is not in the models?  How much are they, you know, are they doing like a cubic fit?  Are they doing something better to project what goes forward?  So I'd love to talk about that in a little later bit.  But before we even get to the AI part, let's talk about what is your view right now on  how data intensive science is being done?  What is the state of that really in academia?  And if you can talk about other disciplines, that's great.  If you want to keep it scoped to climate science, that's great too.  I think this is something that transcends disciplines.  And so data intensive science is the term that I try to use to describe the problems  that we are kind of obsessed with trying to solve in our research group and in our  open source work.  So in a way, we have this ability to generate data right now in science much faster than  we can understand it.  So whether that's simulated data, like those supercomputers are great at generating data.  Like you can run simulations, you know, all day long, dump petabytes of data onto a disk.  And like, there's interesting science in that data, whether it's turbulence or, you know,  molecular dynamics or, you know, drug discovery or whatever.  And likewise, with sensors, you know, with satellites, drones, new observing platforms.  In the ocean, we use autonomous robots that have sensors.  They're just floating around, diving up and down and sending data back to satellite.  So we have this deluge of data.  And so much of the challenge I see is around how do we interpret and make sense of that data?  In many cases, it involves data fusion, combining data from the robots with satellites or combining  data from the models with in-situ observations.  And particularly, there's huge challenges around the volume of data that we have to  confront now.  And this has just changed in my relatively short scientific career.  It's really just exploded and ballooned.  You know, it is very hard to share and collaborate around large scientific data sets.  Once you're measuring that in petabytes, we have our HPC centers that have a mandate to  provide access to scientists, but they're really fortresses.  I mean, they're designed to keep outsiders away from the data.  Heavy security, strong restrictions on what you can run there.  And what we're really trying to do in science is bring more people into the conversation.  Not just more collaborators from other Ivy League institutions, but we really want to be in  climate science. We want to be involving people from the developing world in that science  because they're the ones who are at the most risk from climate change.  Like we need to be more inclusive.  And the way we're doing infrastructure is not serving that goal.  That's why I and many others are excited about the cloud.  Despite all of the caveats that come with cloud computing, it is a really very much a  democratic space where we can all collaborate together.  And it has the right infrastructure to truly scale to the size and complexity of the data  that we're working.  Yeah, that's really interesting to me.  You know, I have many, many of our podcast listeners are, you know, coming from the private  sector, from industry.  And I think, you know, the general public is probably used to this idea of scientific  data being relatively open and public.  And I mean, obviously, you know, pictures come off a space telescope.  It's published, you know, on all the news sites the next day.  So what is the, so this idea, like if you go to, of course, like, you know, an insurance  company, if you work in IT and insurance company or a bank or something like that, or if you  work for the military and some military data analysis, I think it makes sense to you that  the data infrastructure, the computer infrastructure is a fortress there.  There's personal data, there's like national security data.  But for science, for supercomputers that the public, the public tax dollar is going to  pay for to facilitate science, the idea that those are really locked down environments  is somewhat, that's somewhat surprising, isn't it?  Or I mean, should we be surprised or is like, well, you know, talk to me about that.  So I think those are expensive resources.  But you know, part of the thing that cloud allows you to do is sort of separate the compute  part from the data, right?  So like, traditionally, the way we share data in science is through like the download model,  right?  Like we, like the data provider will make like an FTP server and you can like download  the data, right?  And, and that works kind of, that works fine in the small data regime.  What those HPC centers offer to scientists is a place where their data and their compute  are already together next to each other.  And that's, that's, that's what we want.  But it's a sort of a monolithic service in the sense that like, you know, it's all bundled  together and all paid for and by the same, you know, organization.  And it's really, it's really oriented around the compute, like this, this computing centers,  they exist to like, maximize their CPU utilization, like that's the metric for any HPC center.  Like we were at 99% utilization, like we like we spun the CPUs day and night, like mission  accomplished, right?  And, and, and it, so it's a compute centric vision, right?  But for data intensive science, it's really the data that's, that's at the center of the  workflow and of, and, and that's what cloud is more like, you know, in cloud, really the  compute exists to serve the data.  And cloud has this key differentiation, which is that you have this sort of multi-tenant  architecture, right?  Like we can have one copy of the data and like many people can come and compute on it  under their own, you know, account, under their own bill.  And it doesn't have to be downloaded.  And that's, I mean, that's, we, we take it for granted if you're used to cloud computing,  but so much of science, you know, in so many fields is still about, okay, like go download  like 20 terabytes of this data.  Like that's step one for the project, like put it on hard drives and then we can like  start the project, you know?  And I just think that's incredibly-  I mean, you know, the irony is, so let's see if I figure out how to say this concisely.  When Travis and I were really trying to think about the next step, so 10 years ago, we were  thinking about what is the next step?  What's different about the Pythonic model of computation as we came, as we came from  the SciPy ecosystem and, and how is that different than all the stuff that we're seeing in business  computing when we'd go into our consulting, like a Wall Street or some, you know, whatever  big Fortune 100 company, and they've got some, you know, back-end compute job or some scientific  modeling they need to do.  And what we found was that when we thought about the problem, him and I are both, you  know, I'm, I have a physics background, Travis has an electrical engineering background.  We both came from the SciPy world and thinking about how can I efficiently take this code  and apply it to as much data as possible.  There's very much a SIMD approach, single instruction, multiple dispatch.  And what we found when we started, you know, and I played more, I was more in the kind  of the technical lead architect role in a lot of these conversations.  As you go to Wall Street, as you do kind of traditional, traditional back-end computing,  let's say for business applications, there was not an appreciation for this kind of architecture.  There's much more people would marshal data items, do row at a time stuff, just, it was  completely not a vectorized mindset at all, right?  And so, so we, we were thinking, you know what, really to do the next generation of  problems that are coming, and this is 2009 and 10 that we're having these conversations.  You know, we're talking about, you know, for the next generation of compute problems coming  for the, for the next scale of, of data problems that people have, we cannot do this row at  a time stuff.  You know, like the time you don't do row at a time stuff is when you ship a query off  to the database and you let that be like, you know, some database vendors problem.  But the average Java dev that we've dealt with was like shamelessly going and marshaling  floats and ints and moving them around everywhere.  And it's like, you're spending a million cycles to move one int from A to B, right?  And so we found this like, oh, the best way to talk about this is to use the terms from  supercomputing and scientific computing, HPC, move code to data.  And so you'll find, if you go back and look at some of our presentations, our initial  blaze vision and what some of the thinking that led to things like Dask and Intake and  Numba, it was all about how do you move high level code, the right code to massive amounts  of data, because that's a lot easier than shipping data around and shuffling around  and marshaling ints everywhere.  So then we come around and the whole thing turns around and inverts, right?  Now it turns out that these supercomputing facilities, which is where we would have drawn  these lessons from, the architecture of the facility, right, and the economics of that  facility, their particular metrics and KPIs, if you're a supercomputer manager or owner,  it's utilization.  You're absolutely right.  It's utilization.  You cannot say, I have my computers, you know, here's a, whatever, $100 million supercomputer  and it was 90% idle last year.  Like that does not fly, right?  So they're solving for this utilization thing.  And the way they architected for multi-tenancy was not really around data centrality, data  gravity across multiple different tenants and stakeholders, whereas cloud kind of, kind  of is, you know, like it's closer to it than not.  And so this really, I just, I think it's really interesting, the tension between these things,  but ultimately what you're talking about is that the dynamic in the problem space is there  is data.  There's data gravity.  Absolutely.  There's data gravity.  Because these, these data sets are so large, we cannot be moving them around, we do different  research groups, right?  And now gravity pulls the cloud down, it just pulls up into the cloud, right?  And this is really strong in climate science, exactly as you say, because like in one, on  one hand, like we're really blessed in the environmental sciences in general.  We have great open data values.  Like you mentioned this earlier, like people do not generally hoard data or like, you know,  just sit on data.  Like it's all about sharing data.  We have very strong policies from the top down of, from our scientific agencies, our  data must be made open.  And we have this really strong culture around fair data, findable, accessible, interoperable  and reusable.  And this has pervaded the field.  And yet, on the other hand, like, we don't have an actual platform to enact that, right?  And so there's this big sort of debate going on in science right now, what is our architecture?  Like what is, what is, what is our like, field wide architecture we will use to empower people?  And like, there's a bunch of experimentation going on, right?  You've obviously got like the traditional HPC, you know, camp that they're really good  at what they do.  And they, you know, they want to become the data facilities, right?  For, for the field.  And then you've got, you know, people like me who have been like experimenting with cloud  computing.  And I think, you know, to some I'm perceived as like this big cloud like advocate.  They think I'm on like Amazon's payroll, like trying to like get everyone to move to the  cloud.  You know, it's really just about like, what does this technology enable?  Where I think things are headed that I'm pretty excited about is more cloud like  infrastructure, but not necessarily owned, like all by AWS.  So what to give an example of this one project that I'm super excited about is something  called Open Storage Network.  It is a collaboration funded by the NSF and Schmidt Futures.  It's run out of San Diego Supercomputing Center and National Center for Supercomputing  Applications.  So like pretty much from the HPC world.  But what they're doing is they're building object storage.  They're placing it on the Internet with really high bandwidth configurations.  Like it's S3 compatible.  You can hit it from the cloud.  You can hit it from the HPC set centers.  Everybody can compute on it.  You don't have to download the data.  And it's really enabling this sort of like, you know, data fabric for really much more  flexible workflows.  And I'm really excited about that sort of thing.  And I want to see that grow.  It's a bit of then becomes a bit of a social and political problem of, okay, who should  own that?  Whose job is it to provide that infrastructure?  Is it the university?  Is it the agency?  Is it, you know, each scientist pony up, you know, 20 bucks a month?  Like no one has figured out actually the business model.  Yeah.  And I think there's, well, it's there's so many different laws here, right?  If you think about Alan Kay's statement that people are serious about software, need to  make their own hardware.  And I would append that with a corollary to say in this case, since you're serious about  the software, you need to be, you get serious.  You're making your own hardware choices, right?  You're saying I'm not actually wed to this particular thing.  And there's also this kind of thing where, you know, in technology, we can look at things  in tiers.  Like here's the strata of the software, this is the software layer, or this is the platform  layer.  But at the end of the day, those are all just models.  We layer on top of a pile of silicon energized to go and basically run a finite state machine  really fast.  Right.  And so when you look at it in that perspective, the only reason, isn't the only reason that  we would have these separate supercomputing facilities be that we have some different  kind of exotic hardware.  If they're using vanilla, like for a while it was like they had exotic hardware.  Okay, sure.  And then it was like, well, they've got commodity chips, the same chips that you find in a server  on cloud, but they have exotic interconnects.  So sparse matrix problems or other kinds of things, you know, your NUMA architectures  and RDMA kind of things, let you do problems in a way that you cannot do in a generic kind  of thing over here.  But then you actually, good friends of mine are the ones from cycle computing.  We're doing supercomputing applications in the cloud 10 years ago, either pioneered that  kind of that kind of thing, and they have bought by Microsoft.  And that's, it's like they were showing the feasibility even 10 years ago of doing these  big supercomputing jobs in the cloud.  And so as we move forward, I think there is like, if we, if we zoom out past the budgets,  past the organizational political dynamics and all the things, and just ask the question,  what is in the best service of science?  What is the best service of reproducibility, agility, compute efficacy, and all these kinds  of things?  And it's an open question as to why would someone run their own infrastructure?  And I'm not saying, I'm not asking that in a rhetorical sense, I'm asking that a real  sense.  What are some reasons why one would run their own infrastructure, actually be racking servers?  What's different about the servers you're racking versus the data centers that Amazon  or Azure or Google or whoever is racking, right?  Is that a rhetorical question or do you want to go into that?  Well, I don't know.  I am actually interested in what you think are reasons that would get you off the cloud  to prove to us you're not on the AWS payroll.  Well, I can tell you about some of the things that some of the, that a lot of the scientists  I talk to worry about when we say, let's move our infrastructure to the cloud.  A huge one that comes up is egress.  People are very worried that we've put our data in the cloud.  We won't be able to get it back, right?  I think a lot of that is a little bit unfounded, but like there's definitely like the idea  that that business model is to build a moat around this data that was ultimately collected  through public funding or generated at great effort through the scientists.  It doesn't gel.  Whether or not it's a valid technical argument, it's a very strong sort of psychological barrier  for people putting a lot of data into the cloud.  So whatever we can do to get rid of egress fees, and there's stuff happening around this,  like Internet2 and all the cloud providers have sort of egress waiver agreements, treaties  to not charge egress.  So that's one.  And then, you know, there's a lot of fear about lock-in, you know, up to the cloud,  like the idea that we're going to entrust this really precious scientific enterprise  to this company whose values might not align with ours.  And I think the solution there is to just, I want cloud to be as much of a commodity  as possible.  I really don't want a lot of specialized services that are very bespoke to each cloud provider.  I want compute, storage, a few database, a few basic things, and I want them to run really  well and be cheap.  And I want there to be competition in a marketplace, same way that we do for electricity, right?  Like it's a utility.  So that's how I want cloud to be.  I don't think that's how AWS wants cloud to be.  They want to differentiate and add value and stuff.  But there's always that tension there.  And so, you know, those are some of the issues that I see.  Yeah, yeah.  So around the egress thing, it occurs to me that you could, much more cheaply than keeping  a data center up and maintaining it and all that stuff, you could pay, you could require  the hyperscalers, the cloud hyperscalers to do something like, like AWS has their Snowball  thing and there's also, they actually have Snowmobile, which is literally like a 40 foot  shipping container full of hard drives.  I think it's a hundred petabytes in there.  So you could require that the NSF funds or there's some kind of escrow thing or something  where you have the right, you know, a few research institutions who were the recipients  of the grant, they have the right to require a data, like a, almost like a data escrow,  like an open data escrow thing.  They just need an 18 wheeler full of hard drives to be delivered at the end of the contract  or at some period of time to get updated.  So there's, I think there's ways around this, right?  It's not that we don't have the technology, but I do understand those concerns.  And it's a good concern.  You really, you don't want all of science to be captive or to be contingent on a few,  you know, centralized providers.  So that's, that all makes good sense.  I've just, you know, I guess for me, you know, I always try to boil things down to a moral  point, which is the number of brains that can think about the science and the scientific  computing code and the infrastructure and the all whatever.  And they commit their lives to doing the hard work of, it's sometimes very thankless work  of research science.  Those few precious souls, we need them to be doing non-commodity things.  We need them to be cutting, doing cutting edge things, right?  Not sitting there doing stuff that is absolutely commoditized by the hyperscalers.  Just like we don't have them soldering chips or trying to design their own freaking, you  know, like floating point units.  That just doesn't make any sense anymore.  But I think this level of infrastructure, I think that the commoditization point has  moved beyond this at this point.  Totally.  I really, I really dig what you're saying.  This is also what I like to get back to sort of the pi data ecosystem, right?  I think this is just in terms of now just focusing on software, like I think, you know,  pi data has really started to really penetrate into the mainstream science.  It's probably now the dominant stack for in my field, but Matlab is like a probably a  close second.  And, you know, but still, I think what we see is a lot of people are using the SAC at  a very basic level.  They're using like NumPy and Matplotlib, right?  Right.  Which, you know, at the level of functionality is not really that much different than what  you're getting in like basically any scientific computing environment, you know, language,  Matlab, IDL, R, you know, like you got your arrays of data and you can like plot it and  then the rest is up to you.  Where I'm really excited about our stack is the layers, the different functionality that  can be built, you know, that doesn't then have to be rewritten and repeated and recreated,  you know, by grad students over and over.  You know, I see this as the story of the Pangeo project, right?  So just for like a little history on that, like I'm a core developer on X-Array and back  in I think 2016, like we were having this discussion on the X-Array mailing list, like  hey, like X-Array is really great for climate science, like wouldn't it be great if we could  coordinate our efforts and try to raise awareness about it and also add features, add functionality  and sort of grow this community so that everyone else that we know in this field can have the  same superpowers that we feel like we have when we're using X-Array.  And so that's what led to the Pangeo project, which is like, it differs from something like  Astropy, which where they were writing actual software, like under the name Astropy, like  Pangeo was all about integrating that software and to some degree marketing it to both our  funding agencies and our colleagues as like a solution to some domain specific problems.  Like a typical specific problem that it would address is like, okay, NASA is distributing  like data about like ocean temperature and there's like one file per day and there's  like 20,000 files, right, going back to like the beginning of the record.  And like, we want to like query that as one object, right?  And so when we bring to bear like, and we want to do something like calculate statistics,  like what are the trends?  Like are there more marine heat waves shown in this data?  Like are there, you know, are habitats for fish and other green life gonna change, right?  Like the combination of say like X-Array, Dask, HoloViews, like this whole sort of higher  level stack, and then you can bring in XAR if you want to really optimize your storage,  just makes those calculations turn into like one liners, right?  Like things that before we were writing like hundreds of lines of code, like looping through  the files, writing the aggregations, like figuring out bespoke parallelization strategies,  they become like one liners, like, and that's what we've been really trying to sell.  And I think that's where, you know, there's still a lot of work to do to educate users  and different communities about how powerful like higher layers of the PyData stack.  So that's really interesting because when you think about scientists, right, scientists  are, they're busy, right?  They have lots of things.  They want to work on their research.  They want to work on their science.  But when it comes to the, you know, software, some scientists take it seriously.  Most see it as a means to an end, which it kind of is.  And yet you could say the same about math, right?  But you would find it insane to think of a scientist actually arguing that, oh, well,  I'm okay with arithmetic.  I don't really need algebra, or maybe I know algebra, but I don't need trigonometry, it's  certainly not calculus.  I'll have someone else do that.  Or when I really need it, I'll go read the books or something.  And you know, that seems insane.  But what you're saying is, I think, somewhat in line with this, right?  That there is a computational skill literacy something, almost like any other skill they  would use, but not quite, maybe it's not quite like the other skills.  Like making good slides, being able to, they have to learn the tech, they have to go and  write their papers in it, right?  And so this idea of putting a little bit more effort in to help your own brain being augmented  by the computer, the brain-computer interface really is what the programming language is.  Optimize that interface, go from 4-bit to 8-bit, maybe to 16-bit interface on that bad  boy.  Stop beating your head into four, and in four loops and numpy to load mpz files, and do  something a little better.  And I think some of it is marketing, right?  Your point about Pangeo being somewhat of a marketing effort, somewhat of education,  a community, moving the whole community forward.  That's very, very, it's very sort of forward-looking of you to realize that yes, developer, open  free developer tools actually need to have marketing.  You know, who knew?  But it's a thing.  And one thing we did crack with that effort that I really want people to replicate is  we figured out how to get the NSF to pay for sustainable, truly valuable open source  software development.  And we did that by bundling the software development together with scientific use cases, and then  partnering with Anaconda, you know, at the start of that project, where, you know, we  were outsourcing a lot of the development work.  Not all of it, but there was a real partnership.  You know, if you want to think of it from a traditional product point of view, we as  the scientists were sort of acting as, you know, kind of, to some degree, the users and,  you know, the product owners who had certain requirements.  And we were iterating quite quickly with people, you know, Matt Rockland was very involved  early on, and, you know, Dask, and, you know, Jim Bednar, and the Hall of Use tools.  And you know, this iteration was pretty productive, and it left behind, instead of creating new  software, we augmented what was already there.  And that's a pattern that, in general, NSF funding hadn't been able to unlock.  And I think we've found a way to do it.  And I want people to just repeat it over and over.  So I just, if anyone's listening, you're a scientist, and you want to do this, like,  write a proposal to your agency that focuses on like science outcomes, that has a big chunk  that says, okay, here's software dev we need to do to get those outcomes, and then partner  with one of these great open source, you know, shops, whether Anaconda, or, you know, QuantSite,  QuantStack, MakePath.  I mean, there's a lot of great companies out there that can do really high quality dev  work fast, much faster than you can hire a postdoc to do it, and just iterate.  And you do that for three years, and you can really move the ecosystem forward.  And I think, you know, it's a good model.  Well, I definitely appreciate the kind words.  And I think that the collaboration part of it is actually one of these things where it's  one plus one equals three.  I appreciate we're talking about science, I just gave you invalid arithmetic.  But it really is that partnership of the scientists, actually, in that collaboration, the scientists  don't have to choose to be these hybrids of like, am I a software developer now trying  to do maintainable, good software architecture, or am I a scientist actually thinking about  the science of what I'm doing?  In these kind of partnerships, the folks, you know, again, whether it's Anaconda, whether  it's one of these other companies, we do have an eye, we have an experience, we have an  eye towards thinking about what is sustainable, good architecture, or what we may even push  back and say, you know, this is not actually an appropriate thing to try to build as its  own standalone project, you probably should have this as just either, you know, just a  part of what you're doing for this particular research project, right.  And, and so we can give that kind of feedback as well on things like this.  I think that's, you know, that's the kind of thing that I absolutely agree with you  would be, we love to be part of those kinds of things.  And we're, you know, we do some of that kind of stuff on our services work for big enterprise  companies, you know, we're helping them to build and tweak internal dashboard and kinds  of things, or whatever kinds of stuff doing predictive and data scientific sort of work.  So it's definitely an area that we want to help in.  And, and science, you know, the climate science stuff is like, I guess all science is impactful.  Well, you know, with this medical research, there's all these kinds of amazing things  happening right now.  But climate science is the one that I think so many people understand the importance of  now, right?  Like, every, it's just hard to say after the last several years, I can't imagine anyone  is got their head in the sand, you know, about the fact that it's real, things are changing,  and we have to be able to predict what's going to happen.  Otherwise, we'll be caught very, very unawares when hundreds of millions, I'm talking about,  you know, these are like sovereignty ending kinds of catastrophes that could happen and  impact hundreds of millions of lives.  And so, in this regard, what are the, I mean, is there anything like in the climate science  arena?  I'm glad here, it's all open, there's so much open collaboration and the ethos and all that.  But are there aspects that you think are set to really change our understanding in a dramatic  way?  Are there things that are, you know, going through an inflection point?  Or are there like big things on the horizon, that, you know, if we could do the right kinds  of scientific computing, infrastructure, modeling, all that stuff, that we could dramatically  advance and improve, you know, how we're approaching climate science?  Yeah.  So, I think one trend that we have to definitely pay attention to in climate science is the  emergence of a real private sector, right?  That's something that's super interesting.  Because when I got into oceanography, you know, starting in 2006, I mean, I thought  of it like, think of astronomy, right?  Like astronomy is a beautiful, rich, fascinating subject, like it doesn't have a lot of direct  bearing on like our economy, right?  But it's rich, great scientific problem.  And that was really where I was coming from in oceanography.  I just love to look at the data, try and understand what's going on, turbulence, all this.  But in that period, like the realities of climate change have really emerged from the  noise.  And so, we have the internal variability, which you can think of as the noise.  And then there's a forced signal that's, you know, the response to our greenhouse gas emissions.  And that forced signal is getting more and more clear, and it's only going to accelerate  going forward.  And so, we're seeing society respond, and we're seeing the economy respond, and we are  seeing business respond.  And unfortunately, our government has been pretty much inactive on this.  The big climate bill, the inflation reduction bill, whatever they had to call it to get  it passed, that's going to make a huge difference.  But even before that bill passed, business has been mobilized, because they know the  impacts are going to be felt on their bottom line.  And so, we have this whole climate tech sector with, you know, hundreds of billions of dollars  being invested.  And this is a really interesting time for climate science and climate data, because  all those companies need data.  They're working with the same data sets.  And so, we have this scientific infrastructure that's been oriented towards just academic  research that now also has to serve those business needs.  And that's creating a lot of opportunity, it's creating a lot of tension, it's creating  a lot of interesting times for the field.  Yeah, that is an interesting thing, because I feel like when companies are themselves  looking, using this data to make predictions about, you know, logistics or insurance, reinsurance  and things like that, you can see a lot of that stuff where people are, they're still  sharing of this data commons, right?  But then at some point, I wonder if there's something a little bit darker that could creep  in where data withholding and things like that are part of the model advantage, or some  data quality leading to model quality becomes a part of the competitive advantage, not just  de-risking, but actual competitive advantage for some of these enterprises and whatnot.  It's a little bit of a moral hazard, right?  Because if you know that a certain thing, if you know a particular area is more likely  to go underwater and you don't tell them, you're just going to use it to make a little  bit more money on your premiums or how much you, you know, model certain mortgage portfolios.  Like that seems, this seems like there's a moral hazard there, isn't there?  Yeah, I mean, walk me through that a little bit more.  Where do you see the moral hazard?  Well, I just think the moral hazard is like, if you can do accurate modeling of something  where you know, it's going to have a human impact, there's, it seems like there's some  kind of obligation for you to tell people about that, right?  To say, you know what?  Don't use the NOAA model.  Don't use the NASA model.  We have a much better one, which can predict, let's say the storm track.  And we can give people 12 more hours of warning.  Don't you have a moral obligation to then make that model open?  You're referring to the case when like a company would develop that model?  Yes.  I'm talking about the privatization of research enterprise.  Yes.  Yes.  Yeah.  Exactly.  Excellent.  That's really interesting.  Okay.  I totally get what you're saying.  And absolutely it's true.  And then that idea of IP and proprietary knowledge comes into direct conflict with the open data  ethos of the academic research enterprise.  The truth of the matter is right now, and this could change, but the private sector  is not really capable of making climate projections for the simple reason that, remember those  HPC centers we were talking about 20 minutes ago?  They don't have those, right?  And that's actually where all of the climate projections originate from.  And they can talk all they want about using AI and this and that.  But even the same with weather prediction, no one really is running a real weather model  outside of government labs, like the way the National Weather Service does or the European  Center.  So I mean, we could get there, but we're not there today.  Most of what these companies are doing is taking that data and enriching it somehow  or fusing it with other data.  In terms of the moral hazard, yeah, I mean, I think it's real.  I think it's problematic if companies are using some specialized knowledge about the  climate to, say, help Goldman improve their portfolio, but not help children in Bangladesh  avoid catastrophic heat waves or something.  But the fact is, I believe interests are aligned in almost all cases, right?  So in terms of adaptation to climate change, we've seen what happens to people when supply  chains are disrupted, like empty shelves, like diapers, that's a case where everyday  people's interests and business interests are highly aligned to keep those supply chains  functioning.  And that's why supply chains are a big place where climate change is going to be a very  direct impact.  Well, this is, no, of course, right?  This is an interesting area.  And I think about this now, we're going to go like two levels up on the philosophy of  the economics and the politics of this.  You bring up Goldman, which is, of course, they are very active and they're a very renowned  firm in the space of financial services and investment banking and prediction of sort  of financial things.  And one could argue, of course, that when traders are out there, this is not really  about Goldman, it's just about the way that the financial sector works.  When traders are sitting there, they're shorting this or they're arbitraging that, they're  making predictions and the way they allocate capital affects people's livelihoods and people's  lives.  So there is a human impact to what they do, no doubt about it, right?  But that being said, the data they're trading on, ultimately it's a big casino.  They're still making a bet, they're taking a position.  There's some arbitrage available, various kinds of things.  But at the end of the day, they're having to take a position on what the future may  look like.  And it's through a cloud of, there could be geopolitical risk.  There's all sorts of things, who knows what people are buying or not buying or watching  or not watching.  But when it comes to something like the weather, we now have a prediction environment, a prediction  problem that is just as materially impactful as, I'm sorry, I said weather, I should say  the climate.  When it comes to climate, right?  That's a data centric prediction problem that is just as impactful as anything is trading  signals off of Wall Street.  But there is, to me, it seems like there's a much clearer connection between the value  of this as a commons, good modeling, good prediction as a commons, as opposed to it  being a scarce resource for people to go and try to arbitrage each other on.  And this is the thing that we're going to have to figure out because I think it's not  just climate, so many other things as they come online, as predictions become more and  online part of how businesses are making decisions about logistics, about customers, about all  these things.  Okay, Peter, let me interrupt you for a minute.  I see where you're going about this potential divide that could emerge between the companies  working on this and the rest of the world.  And I really do think it's a problem that can be solved through effective cooperation  around both the data and software commons that all of the stakeholders in this problem  have, right?  So we want to incentivize companies to find solutions to climate change, but we don't  want to do that by having them build a wall around common data or around tools that can  benefit everyone.  And everyone I talk to who's operating in this space feels that way.  It's not that they're in it to get super rich, they're trying to use the market to  drive innovation and find solutions.  The academic climate research enterprise needs to meet them halfway by thinking about things  like data infrastructure.  If we make our data systems so inaccessible and obscure, then there's going to emerge  a whole sector of this industry that's just going to repackage and resell the data to  people.  And you can already see what's happening in the crypto space.  You can go read about all this climate data you can get on Web3.  They say, the NASA data is so obscure and weird, it's not usable by business.  Join our coin and we'll give you clean climate data to integrate into your apps.  Let's not do that.  Let's not do that.  Let's, as a research enterprise, make our data system so great that it's easy to use  for scientists to make discoveries.  It's easy to use for businesses to leverage that data that was collected through taxpayers.  And let's make it easy to give back.  Right now, the data exchange is pretty one way.  Generally NASA and NOAA are collecting a lot of data and generating data and others are  consuming it.  But I'm really inspired by companies like Planet.  They launched their own fleet of satellites and they've been a really good citizen contributing  a lot of open data back to the community.  A lot of great software and infrastructure work has come out of Planet.  So if there are going to be more companies like that operating in this space, I am very  optimistic about the future.  But we on the research and government side have to meet them halfway and modernize our  infrastructure.  Yeah, no, I think you're absolutely right.  We sort of noticed this a little bit in the software side on the open source stuff, too.  We produce a lot of this great scientific software that's fit for purpose, is made by  scientists to solve their own problems.  But if it's hard to use, no one adopts it.  They will go to a cloud vendor that, or I won't say cloud vendor, but they'll go to  any vendor that cheesily repackages it cheesily and says, well, here's an easier thing.  And so I do think actually this way, right, with Anaconda, making some of these easier  to install was a way to kind of prevent that from happening.  And I think with data, with models, the same thing has to happen.  The whole community of maintainers, people believe in the necessity of this being open  and being an open commons.  We have to really respect what the end users needs are and go an extra mile to make it  easy for them to participate in the way that we want them to show up, right, in this kind  of ecosystem.  Otherwise, others will step in and then direct them kind of whatever direction.  So that's a really great comment.  I'm so sure you're giving me some hope in that regard.  Can I tell you about our Pangeo Forge project, which is trying to help solve this?  Okay.  Okay.  So probably most of your listeners know about Conda Forge, right?  So like, Conda Forge, you know, they really democratized the sort of production of Conda  packages by creating a sort of cloud-based environment where you could provide a recipe.  You didn't, you know, before Conda Forge, you could build your own Conda package and  compile everything up and like put it on the website.  But like Conda Forge made it even easier to contribute to like the library of Conda packages.  And that really opened things up.  And I think, you know, it's really cool.  Now, Pangeo Forge is trying to do something similar with analysis-ready data in the cloud,  right?  So a lot of the data engineering work in this space means taking data in some archival format  from some data provider.  Let's just pick NOAA, you know, NOAA is great.  I'm not trying to pick on them.  But they basically have an FTP server full of a bunch of files in some obscure format  like GRIB, you know, that you can, you know, download.  And what we want is essentially we want that in a database or a data lake, right?  Where they're accessible to compute, ready for analysis, where we don't have to do a  bunch of data engineering legwork just to get to our first plot.  So that kind of work happens every day in scientific labs.  That's happening every day in these companies we're talking about in the climate tech space.  And it's really tedious.  It's full of toil.  And it's ultimately, you know, repeatable.  Like many people are doing the same job over and over.  And so the goal of Pangeo Forge is to create a sort of data commons, where we can build  this analysis ready data in the cloud, from all kinds of different sources, in a crowdsource  collaborative way.  Right?  So we directly copy the sort of pattern from Condor Forge, and you have a feedstock that  describes the sort of transformation pipeline, where am I going to ingest the data from?  How am I going to transform it along the way?  What sort of format am I writing it to?  And then the back end of the Pangeo Forge just executes those, you know, interfacing  with Git, you know, triggered on commits to the repos, and it stages the data.  And we're populating this library of open access data that's accessible to everyone  can be used by researchers can be used by businesses.  And it's not like one guy who has to, like, manage all the pipelines.  It's a community framework where we can do this collaboratively.  This is a project I'm super excited about.  It's really hard, like, it's very ambitious, and where it's way beyond our capability as  just our team to, to actually realize the potential.  So I, whenever I get a platform, I like to sort of plug it a little bit encourage people  to get involved.  Because like, we could use way more like hands on deck for this project.  But at the same time, it's up to date, it's functional.  And it's really cool what it can do.  So Ryan, that sounds that sounds great.  I know it's think, I mean, look, data munging is always thankless work, right?  But at least you're doing it once, making sure no one has to do it again.  And furthermore, it seems to me like the data transformation thing you're doing here, and  the way that you, you know, handle data, the scientific data formats, the fact that it's  running kind of in this cloud way, but all the infrastructure is open.  That's reproducible.  You clone stamp that for astronomy, you clone stamp that for, you know, so many different  kinds of things, right?  So, so that sounds so I'm happy you plugged it.  I'm glad you plugged it.  And I encourage our listeners to go and check that out.  And also check out xarray, which you mentioned you are now you know, you went from being  a user to being a maintainer developer of right?  Absolutely.  Yeah, I love xarray and I'll hype it up whenever I get a chance, right?  So basically, you know, what xarray is, if people who don't know it, you know, like,  the way we think about the the pi data stack is usually like kind of have like kind of  NumPy at the base, it's like the foundation of everything.  And then like pandas is this abstraction that sits on on on top of NumPy in many ways, like  it uses NumPy under the hood, and it provides things like indexes and group by and a bunch  of like cool features.  But pandas is really oriented around the tabular data model, right?  So in pandas, really, you've just got, you know, your various rows, and you got your  your columns.  And on whereas NumPy actually has you can have n dimensions to any of your arrays, right?  So what pandas ultimately does under the hood is it just manages a bunch of one dimensional  or NumPy arrays.  xarray aims to provide that higher level API around multi dimensional data, right?  So what we get in xarray is we've got to say we've got a data cube temperature on earth,  you know, rather than just thinking about axis zero axis one and axis two, we can think  about time axis, latitude axis, longitude axis, we can have an index on each of those  axes.  So query it not not not by my by by position, you know, integer offset within a nameless,  you know, array, but by give me Okay, give me 2001, you know, at this latitude and this  longitude, we can query the data.  And we can get things like group by, you know, rolling reductions, all of the awesome, you  know, convenience features and that really help analysts, you know, write better analysis  code, write faster analysis code.  And then xarray also wraps many, many different array like things, not just NumPy arrays.  So you've got, you know, Dask was one of our first integration.  So xarray can hold a Dask array.  And bringing those two together, you have this sort of amazing scale out framework for  array computing that I know of no other thing that does that, like, there's a lot of frameworks  that will allow you to do like, bit large scale analytics on tables.  I mean, there's like, there's probably from traditional databases to, you know, all your  sparks and Presto and Trino and, you know, everything does tables, right?  So pandas and Dask data frame, it's just one of two dozen different solutions to that  I know of no other framework that allows you to do like this scale out analytics on array  is the way xarray and Dask do.  It's really a superpower.  Yeah.  And then of course, it's, it's, yeah, it's, it's not just, it's not just the, the multiple  dimensionality you have, but also the fact that it is labeled, right?  That you're, you're able to do really use meaningful semantic indexing on this stuff.  I do understand that all the cool kids call multidimensional race tensors now.  So if you were to call it like hypertensor or something, maybe you get a little bit more  of a more, more an option uptick and a few more stars on GitHub.  But as a computational physicist, I just cannot get behind the tensor thing.  A tensor is a different thing.  Tensors are about symmetries and, you know, properties under, under transformations.  And arrays are just big multidimensional buckets of numbers.  And that's what these things all are.  But you call it distributed buckets of numbers too.  That would also be kind of hilarious.  I see that trending on, on Hacker News, bucket of numbers.  Our ecosystem has made a lot of advances in terms of array, the array API, right?  So now we've got sparse arrays.  We've got GPU arrays, CoolPy.  We've got, we've got Pyte, unit aware arrays.  So, you know, in X-array now, you can do analytics on, you know, X-array wrapping Dask,  which is then pointing at CoolPy arrays and compute on a GPU cluster.  Or you can have unit aware arrays in there.  And the next step that we're working on is integration with the machine learning tensor  libraries.  So PyTorch tensors, Jax arrays, you know, so that you can hold all of those things within  X-array, compute on them using X-arrays API, which people love, and then get along, get  things like automatic differentiation, you know, all of the machine learning and other  features that those array libraries bring.  So we really think of X-array as kind of this ecosystem glue that brings all these other  things together.  And it's kind of the top layer of the stack that so many of us use.  That's fantastic.  And I'm so glad to see that come around.  If we had more time, I'd love to delve a little bit more into a kind of, you know, these global  array concepts, and maybe talk about chapel and some of these other things.  But we're somewhat out of time, but I've just tremendously enjoyed this conversation with  you, Ryan.  I want to thank you for bringing so much energy into it and all the great things that you've  done for scientific computing and for science.  And I encourage our listeners to check out X-array, to check out PangeoForge and the  Pangeo project in general.  And I look forward to future conversations.  Thank you so much for joining us today on the podcast.  Thanks Peter.  It's been so much fun.  Thank you.  And as a reminder to the listeners, of course, in the show notes, you can find links to all  these projects.  So be sure to check out our show notes.  Thank you.  Thank you for listening.  And we hope you found this episode valuable.  If you enjoyed the show, please leave us a five-star review.  You can find more information and resources at Anaconda.com. 