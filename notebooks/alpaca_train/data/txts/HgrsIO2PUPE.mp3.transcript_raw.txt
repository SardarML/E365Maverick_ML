 Good morning, good afternoon, or good evening, depending on where you are, and welcome to  this Tech Strong Learning experience.  My name is Cody, and I'm the host of Tech Strong Learning, and we have an exciting panel  ahead.  Before we kick things off, I do need to cover just a couple of housekeeping notes.  Today's session is being recorded.  If you miss any of our discussion, maybe you'd like to rewatch or share with a friend.  You'll be receiving an email with a link to access this on demand shortly after we conclude  our live session today.  If you look over on the right side of your screen, you'll see there are a couple options  to engage with our panel, the first of which is the chat tab, so I'd like you to start  warming that up for me by letting us know from where you are joining.  For any questions that you may have, we'd like you to direct those to the Q&A panel  to the right side of that chat tab.  And if you click the handouts tab, you'll see that we have the top five Kubernetes mistakes  you're probably making.  It's a white paper provided by Fairwinds.  And as a follow-up from the event, you will be receiving the how to identify security  and reliability misconfigurations in Kubernetes.  And as always, before we close out, we are giving away four $25 Amazon gift cards.  The topic of our discussion today is Kubernetes security.  And I'm joined once again by Robert Brinden, Vice President of Product Development at Fairwinds,  Neil Carpenter, Principal Technical Evangelist at Orca Security, Nung Badel, CRE and SRE  at Fairwinds.  And leading our conversation today is our very own Mike Bizzard, Chief Content Officer  at TechStrong.  So I'd like to thank everyone for joining us once again today.  Mike, do you want to go ahead and get this conversation going?  Great.  Hey, everybody.  Good to see you again.  I think it's fair to say that security was something of an afterthought when it came  to Kubernetes, and we've been kind of plugging our way at it ever since.  I think Kubernetes itself is maybe six, seven years old, but I guess not everybody's entirely  clear what is the current state of security for Kubernetes.  So Neil, maybe we'll start with you.  But what's your sense of where are we and how far have we come in this journey?  And what comes in the box versus what do I got to figure out myself?  So I'm really cautiously optimistic about where we are.  But as I think about it, there are two distinct problems that we throw together.  One is Kubernetes as a platform.  When I set the thing up, do I have API endpoints exposed to the world, unauthenticated?  That sort of problem.  The second problem is what do I bring and run on top of it, and how do I configure it  and build that stuff and all of those things?  The first problem, I think Kubernetes has had a reputation as being somewhat insecure  by default, and deservedly so.  But the good news is I don't think, statistically speaking, I don't think anybody is running  vanilla Kubernetes today, at least not for important workloads.  They're running one of the cloud service providers, EKS, GKE, AKS, one of the other ones, or they're  running OpenShift, or they're running Rancher.  And the good news is all of these sort of, I don't know what we would call them, all  of these Kubernetes platforms have a really strong incentive to get that stuff right.  And so if I go install, let's say, I spent a year at Red Hat, so I'm fairly familiar  with OpenShift.  If I go install OpenShift, the platform is pretty much secure by default.  They've done a great job with that.  If I install one of the cloud service providers, Kubernetes distributions, they're secure by  default out of the box, unless I go make changes to break something and do something foolish.  I'm typically not going to see a lot of problems there, regardless of how many switches there  are in Kubernetes itself.  If I'm setting it up right, or if I'm setting it up using one of those platforms, I'm getting  it right by default out of the box.  What really worries me, then, is what people are bringing and running on top of.  The applications they're building, how they're configuring them, where they're doing things  that they're not looking at appropriate guardrails, and introducing risk by running applications  as root on top of Kubernetes.  There's a million different misconfigurations there, but that's the space that I think is  really interesting to take.  Doubly so, one of the other things that I've seen happen over about the last two years  is that software is starting to be distributed to people as helm charts, or as something  to run on top of Kubernetes.  Now you have this problem of, how do I know what I'm getting from my vendor is in good  shape as well?  How do I approach that?  I'll just throw out one of the first place I saw this, and it's a fascinating space,  but if you don't know this, all of the infrastructure underneath the 5G networks for cell phones  runs on top of Kubernetes.  Your telecoms are getting these packages of container images and configurations from the  upstream vendors like Nokia, that they're then figuring out how to run securely on their  Kubernetes clusters.  It's a whole frontier, and now you're seeing cloud packs from IBM coming in this same format.  All sorts of other things starting to be deployed, starting to be delivered as, here's something  you can run on top of Kubernetes.  That's where I think the problems are today.  Those are the ones that are most interesting to me, but Nung, Robert, what do you guys  think?  Go ahead, Nung.  Yeah, I agree.  One thing is, since Kubernetes is the new word and the new thing on the block, people  tend to just want to focus on the name.  It sounds strange.  It's new.  Therefore, it has new vulnerabilities, but in I think most of the sense, it's back to  container security.  If you have insecure containers that you're delivering, whether you deliver them in ECS  or any other container management system or in Kubernetes, you are still exposing yourself  to the very similar type of attack vectors.  Just put in chat as well, you mentioned Helm charts.  Today we've made aware of CVE that it's targeting Helm charts, so how apropos.  And we didn't even pay them to do that, which is great.  Robert, one of the issues that people run into, I think, when their perception is that  Kubernetes is insecure by default, is that the people who built Kubernetes assume that  there's going to be platforms on top of this and you weren't really going to be playing  with these lower level APIs and yet, surprise, surprise, folks played with the lower level  APIs because they have DevOps teams that were messing around with this, that, and the other.  But do we really need more of a higher level of abstraction to manage Kubernetes security  and what does that look like and is that something that makes the whole security equation more  accessible to mere mortals?  Yeah, no, it's a great question.  I think the companies we've seen be the most successful with Kubernetes do put together  that platform on top of Kubernetes.  So you have a core infrastructure team, a core platform team, essentially setting up  guardrails.  And the word guardrails, I think that's a great word to describe it, that gives their  development teams the levers that they need in order to get their application running  and it allows them to push the responsibility for setting up things like environment variables  and CPU and memory settings onto the development teams.  But those platform teams can control whether things are running as root, whether images  with known CVEs are allowed, things like that.  And it allows a lot of the responsibility to be put onto the devs without giving them  all the, you know, foot guns that come with that.  And we're starting to get a pile of questions going already, so guys, keep them coming.  We will get to them all soon if Neil and Nung want to answer them in the text, great.  If not, we'll keep it going audio or we may do both because not everybody's reading the  text and everybody wants to hear the questions as well.  I guess the next question I would have, and maybe I'll throw this at Nung, because you  brought up this vulnerability, but we are starting to see more Kubernetes clusters being  deployed in production environments.  Do you think the bad guys have figured this out and they're starting to look for these  things and, you know, what's your sense of how savvy are the adversaries these days about  what's going on with Kubernetes and security?  Yeah, I think, yeah, the bad guys are definitely out there and they're the bad guys and gals.  They're figuring out different attack vectors.  They have, you know, they're first trying to figure out if you are running your containers,  where you're running it, and then once they identify that you have Kubernetes, that gives  them a whole other list of things to check off and test for, you know, if any of your  containers and your clusters are privileged and, you know, if they can somehow gain root  level access, you know, and escape the Docker, you know, runtime and then get into a node  and compromise a node.  Because then once they compromise one node, they can do things like, you know, in a large  cluster, start dropping Bitcoin mining agents in there and, you know, utilize all your resources  to fatten their purses.  And as you mentioned that, sorry, I had to go back and look.  So the first publicly acknowledged Kubernetes incident that I'm aware of was in 2018.  And it was Tesla.  There was a ton of coverage of it before GKS, before GKE, before all of the managed Kubernetes  platforms.  They had split up a couple of Kubernetes platforms in AWS, accidentally exposed unauthenticated  API endpoints to the internet, and somebody came along and dropped a bunch of cryptocurrency  miners on them.  Yeah, which I think is sort of the base, you know, using somebody else's CPU to mint money  for you is a very quick way to monetize a compromise like that.  You know, I think we are going to see attackers get better at this.  I think I talked about early in the year when people were asking me for predictions  for 2023.  I suspect this is the year we'll see ransomware affecting cloud properties and Kubernetes  in particular.  I haven't seen a ransomware incident on Kubernetes yet, but, you know, it's an ongoing, it's  the way that attacks are being leveraged.  I think we'll also see over time more targeted attackers going after data that Kubernetes  is managing and using it as a springboard to interesting data being processed in applications.  So all this stuff is coming.  The same things we've seen happen on-prem, we've seen happen against SaaS applications.  It's all, attackers are going to go wherever the money and the data is.  Robert, to follow up on that and to what Noong was saying, do we take the current attacks  seriously enough?  And I'm asking the question because a lot of people think that crypto jacking is a nuisance  crime, right?  It's not really, you know, a serious threat and they probably, you know, ignore it.  And yet it does show that the environment has been breached and more than likely it  seems to me that somebody is going to start selling that backdoor that they created.  So, you know, is there more adventure to come?  Yeah.  And I mean, there's plenty more you can do beyond crypto mining, right?  It's the easiest way to monetize, as Neil pointed out, but, you know, if they can find  data and, you know, sell that data or just sell their access, like you pointed out, Mike,  I think that's all stuff that we should be worried about, right?  You know, Noong said, you know, if they get access to one of those nodes, they can start  mining Bitcoin.  That's definitely true.  You can also see all your secrets that are stored in your Kubernetes clusters.  So your database credentials are in there.  You know, any credentials for cloud providers, cloud integrations, things like that.  You know, they basically have the keys to the kingdom.  So it's there's a lot more to worry about in terms of data loss, in terms of, you know,  consumer privacy, things like that.  All right.  We have a question from one of our attendees about the notion of the base image security.  I'm not sure that we all have a good handle on exactly what the question is, but it seems  to be about whether or not the base image is secure and what's the criteria for choosing  the base image.  And I was just waiting for one of you to raise your hand and Noong was there.  Yeah, I have thought about it.  And I think what the participant is wondering is base image in the sense of code scanning.  You're scanning your repos for any type of vulnerabilities identified by log CVEs.  Then those get compiled into Docker base images or you're grabbing base images from a repo  and you don't necessarily want to just trust the maintainer of the repo that they've covered  all the bases with regard to known vulnerabilities.  So you want to scan those things.  And those are great.  They're proactive, but they still don't protect you against zero day events.  And having implemented a zero trust policy is another tool that you can have in your  toolbox to prevent zero day attacks that image scanning is not going to protect you  against because zero days are they just discovered a new vulnerability.  It's not in your library that you can reference.  So therefore you are vulnerable.  And the only thing to protect you is a best practice implementation in your cluster and  in your processes.  Yeah.  Sorry, go ahead, Robert.  I was going to say, I totally agree there.  And just in terms of, I think the participant asked for criteria for choosing a base image.  We like to go with Alpine because it's much smaller than say Ubuntu image or something  like that.  The big thing I would recommend though is just being consistent, right?  Throughout your organization, use the same base image so that when a CVE gets announced,  you know exactly where to go, what version to update to, et cetera.  So we use Alpine everywhere.  There was a recent vulnerability that showed up in the Alpine image and it took us two  seconds to just run one script, update the Alpine image everywhere, cut new releases  of every image and we were done with it.  Whereas if we were using Ubuntu in half the places, it would have been a lot more tricky  to figure out what version do we need to be on, et cetera.  And I was sort of wondering if maybe that was part of the question as well, was base  OS image.  And you know, I think it is an interesting conversation about sort of Alpine versus Debian  Ubuntu versus CentOS and RHEL.  And I think Red Hat has done some interesting sort of minimal images lately as well.  There's a lot to think about in there because I probably don't, I have the opposite of an  affinity for Alpine because vulnerability scanning in Alpine has been not as perfect  and not as sort of well-documented in my experience as say Debian or RHEL.  So you know, I'm sort of looking at which images do I feel like I can, I can get the  best vulnerability data, the best scanning, the best information about.  And then of course, on top of that, you have some people who go with distro-less images  where you're building from essentially a blank slate.  There's a trade-off there.  That is incredibly minimal and that's sort of one of those, you know, microservices approaches,  but I think it makes it much more difficult to troubleshoot and to maintain and to figure  out what's going on with those images.  So yeah, I don't have a single answer, but I think these are important questions to consider  as you build something and probably to build something like Robert said, that's standardized  across your org so that you're not fixing a lot of problems.  Why is it that Alpine doesn't seem to get that kind of love?  Because I, you know, when I was working closer with developers, it feels like we like the  Alpine image because it is so minimal.  And yeah.  All right.  I think we're taking a memo and sending it to somebody.  Hold on.  Yeah.  I mean, I'll give you an example.  I was working on a comparison recently where two different vulnerability scanners, one  of them came up with an image or with a CVE in an Alpine image and the other one didn't.  And it was an argument over whether it actually applied to that image or not.  And we had to dig into, we had to dig really deep to come up with an answer.  And some of the documentation seemed to suggest that this vuln applied.  Some of it seemed to suggest it didn't.  And we finally came to the right answer.  And the right answer was it didn't apply because anyway, they didn't include this particular  module in BusyBox, thus it didn't actually apply.  But the data was not consistent on it.  So it was just, it was difficult to answer that question.  And that's the stress that kills everybody because of that amount of time when you don't  know for certain what's going on and you don't know what the response should be and you're  in limbo and that's when everybody's kind of starts losing their mind, right?  Yeah.  Robert, let me ask you this though.  We talked about zero-day vulnerabilities and my question to you is, in a platform like  this that's relatively new, should I expect the unexpected in the sense that there are  going to be more zero-day events because it just is a new platform and it's kind of part  of the ride that I bought the ticket for?  Yeah.  I mean, Kubernetes itself at this point is fairly stable.  I don't think we've had a major Kubernetes, like core Kubernetes vulnerability in the  last year or two, at least a critical level one.  And it is nice that the cloud providers do, if you are using EKS, GKE, et cetera, the  cloud providers take care of a lot of that for you.  They can upgrade for you.  They kind of force you through upgrades a little bit, which is nice.  The place you should be worried about those zero-days popping up is inside your container  images more than anything.  There's a lot going on inside each of those container images.  And yeah, I mean, there's new vulnerabilities being announced every day, like today with  Helm, vulnerabilities in Git and all your dependencies for your application.  If you've got a bunch of different containers running in prod, which every Kubernetes cluster  has at least a few dozen, there's vulnerabilities popping up all the time and staying on top  of those could be really hard.  All right.  We're going to go around Robin in a minute for your pet peeves for Kubernetes securities  and things you wish people wouldn't do, but I'm going to take one off the table immediately  because mine is the assumption that the container is only going to be running for a few seconds  and no one's ever going to see it.  And therefore I don't have to worry about its security because meanwhile, we're going  to re-instantiate that same insecure container five seconds later, right?  But that's just my favorite.  Nung, we'll start with you.  What's your kind of favorite pet peeve of the day that you wish people would kind of  think about more and so you wouldn't run into it as often in terms of help calls and support?  I guess I'll take the one I mentioned earlier, just running as root and not developing your  container to run as a user, fundamental.  Can you explain or do you have any insight as to why do people keep running stuff at  root?  I mean, we've been telling them not to do it forever and a day and it still happens.  Well, it's easy to develop as super user.  You can do anything you want without any system telling you, nope, you don't have access to  this.  So yeah, I think it's a habit that some people form right from the beginning because you  develop it on your computer and you run it there and it worked on my computer, so it  should work anywhere else.  And yeah, they don't get around to hardening it or testing it.  Just a second thought, ship it, feature, get that out the door.  I want to be done, winds up being the most troublesome thing there is.  Neil, what are your thoughts?  Is there anything out there that you look at and you go, wow, this is just, we're better  than this.  Yeah, this may not be a single pet peeve, but I find that security architects when they  approach Kubernetes focus on complex solutions and they forget about the simple.  So I've talked to a lot of people as an example who were really super focused on like Istio  and service mesh and things that are a 18 month journey for a reasonably strong organization,  but they didn't have vulnerability scanning and sort of posture management in place, right?  So generally speaking, I want people to focus on those simple wins first.  Build up, get 80% of stuff covered before you worry about the most 20%, the most complex  20%.  Right, because the bad guys aren't going to do any more than they have to do.  Right.  I mean, most of them, it's running from the bear, right?  I don't have to run faster than the bear.  I have to run faster than you.  There you go.  Robert, any pet peeves?  Yeah, I would say my big one is, you know, as a developer, I really want to see, you  know, the platform team put guardrails in place to help me understand, you know, what  I need to do in order to get my app running securely, right?  So don't mention like developers, they just want to run it as root because that's the  easiest thing to do, right?  What I want are guardrails in place that say, no, you're not allowed to do that.  You can't ship your application until you fix X, Y, and Z.  Because that helps me, because I, you know, I mean, I, since I'm a Kubernetes developer,  I understand Kubernetes well, but your average developer doesn't really know what it means  to run as root versus non-root.  They don't know about running as privileged, things like that.  We don't know what we don't know.  So having a platform in place that's going to give us warnings or block our deployments  when we're trying to do things that aren't secure is super helpful because I don't need  to go, you know, reading all the Kubernetes documentation and become the Kubernetes expert  in order to get my application running.  We have a question from the audience who wants to know if there's any specific security concerns  about accessing Kubernetes from a browser that they might want to be thinking about.  Is there anything in particular, Neil, that comes to mind there when you look at that or?  You know, I think sort of all of the typical concerns are going to apply there, right?  If I'm getting to Kubernetes and they said CLE, I'm not sure if they mean CLI,  like using, you know, using, I don't know, Google console and opening up the CLI  and starting to type kubectl, you know, I mean, first of all,  authentication is a big deal there, right?  If I can access, if I can get to the control plane through a browser,  I want to make sure I'm properly authenticating and authorizing the people who are doing that.  And, you know, I mean, typically, like I use lots of cloud services in a fairly insecure way  because I'm an architect, I'm not, or I'm an evangelist now.  I'm not doing anything production ready.  I'm just demonstrating stuff, right?  So I have a Google cloud account right now that doesn't have MFA turned on.  I shouldn't announce that out loud, but I don't have anything risky there.  All of my ops people and developers and engineers absolutely have MFA  and have everything properly locked down to make sure that that access is valid.  Typically, I would take that a step further.  I would only want to ever be able to access clusters that were not production directly.  If it's dev, if it's test, that stuff is great.  Pound at it, you know, make sure it's properly authorized and authenticated.  But, you know, in a perfect world, I think production clusters should never be touched directly.  They should all be behind pipelines that manage everything.  And it should all be sort of rational and automated and not have human hands touching it.  All right, Robert's head is going up and down in violent agreement.  So you want to add something here?  Yeah, no, the thing I'll add to build on that is utilizing role-based access control.  So making sure that the right people have access to the right stuff and only what they need access to to do their job.  Right. So, you know, you may you may give, you know, one or two SREs access to those production clusters.  But you don't want to give that to every single one of your devs. Right.  Those devs should maybe have read-only access to production or they should have, you know, access to certain resources, but not others.  You don't want them modifying things in Kube system.  You only want them modifying things in their namespaces.  So it's kind of up to you how you want to partition out all that, all those roles, but making sure you have separate roles for devs versus SREs,  making sure you're, you know, tightening down the admin role as much as possible.  Things like that are super helpful.  Now, who's in charge of Kubernetes security these days?  And I'm asking the question because we got a movement to shift left.  We got a movement to shift right to put more of the responsibility on the IT operations team.  And then, of course, there's the security people.  And sometimes I feel like I'm watching a baseball game where the left field and the center field and the shortstop are all screaming, I got it.  And the ball just drops in the middle. So what's your sense of who's in charge of this thing?  Well, yeah, it's kind of funny as you talk to the infrastructure, me coming from the SRE side, right.  I'm pointing over to or down to the developer.  And then when Robert gets the question, he points up to infrastructure with guardrails.  And yeah, you're asking shift left, right.  So the first line of code gets written by developers.  That's as far left as you can go.  But maybe you can go further left with possibly, you know, the business design and everything like the management getting behind putting in guardrails.  So that's the infrastructure team being involved.  And then back to developers.  But I think the responsibility is the entire company, because you can't just leave it up to one team to think of all of everything.  Let the developers focus on their code, their delivery product, the container.  But then have the infrastructure team to get their back by putting in guardrails, implementing policy tools, you know,  an open policy agent admission controller so they can't put in containers that have vulnerabilities or leave back doors open.  Check for those things, because you're going to do that anyway.  So might as well create some kind of automated or utilize an automated tool that does that in your cluster.  And again, you're going to do this whether you're using Kubernetes or not.  So it's just I think the whole thing just shifted where folks were looking at all the different cloud services.  And remember when cloud was new?  Well, cloud's not secure, because cloud was the new buzzword.  And everybody was like, well, how do you make cloud just as secure as on-premises, bare metal?  The same attack vectors are there, maybe more, and you're discovering them.  And same thing with Kubernetes is you go through that whole list of existing attack vectors and services,  and you're identifying them in Kubernetes.  And then comes where the big money is, is thinking like a hacker and discovering what are the new services that can be exploited.  Neil, what's your sense of the state of the art on the shift left?  Because frankly, most of the developers that I know, if they got any exposure to security, it was an elective and they didn't take it.  And then we're surprised when we give these guys tools and there's misconfigurations.  So what's real here?  Yeah, and honestly, I hope that's not the case anymore.  The SDLC is what, like 20 years old now?  So hopefully our developers have started to be exposed to security every day and as part of their process.  The state of the art for shift left for me, and this ties into the question you asked, Nung, and Nung's response is,  for me, DevSecOps is a marketing term, but it's a very real place that we've ended up.  As we've moved from a world, 20 years ago, we used to launch software every 18 months or two years.  And there was lots of time for development and then security to come in and do things.  We've now gone to the point where I talk to people who are launching new software, new updates daily, sometimes every few hours.  And so that cycle is shortened.  We've got to get security into it to stay ahead of it.  We don't want to ship things that get compromised, right?  So for me, the state of the art and shift left, tying this all back to your question.  The state of the art and shift left is where my security checks, my guardrails show up in the same way as I'm doing other automated testing in that pipeline.  So I check something into GitHub and there are a bunch of things that run, you know, it might run a linter to make sure I'm not writing terrible Golang,  which I would because I'm not a developer, but, you know, or whatever else.  But at the same time, we start running security tests to say, oh, well, in your go.mod, you've got this package, which has these known vulnerabilities.  You need to update to this and then integrating that all the way along.  When I build my container image as part of my, you know, CI CD as part of delivering that into dev test prod, I'm going to have integration testing and unit testing and performance testing and all these sorts of things.  And as a developer, I know if I, I don't know, if I ship something and it breaks my test, I'm going to have to go fix that before I can actually push to production.  Where I see this work is security shows up in the same way.  If I ship it and my container is running as root because I haven't included a user directive in it, it breaks and I have to fix that before it ships.  And so now we're, we're taking all of these security concepts, we're taking policy and we're turning it into automation that works in a way developers understand.  And so for me, that's, that's powerful.  That's where we really get to where we're going.  Um, and, and I saw, I saw a company that did this, they started on this journey about two years ago.  They did such a great job of building it into it that all the developers now just understand this is, this is the way it works.  I have to pass these security checks to deliver something in the same way.  I have to use spaces, not tabs or tabs, not spaces or whatever, whatever your, your thing is right.  It just, it's just automatic.  It's built in, it's right there.  And it's very clear what you've done and what you have to do to fix it.  Robert, do you think that the adoption of Kubernetes and the complexity and the awareness of what's required for securing software supply chains is in some ways helping to force the DevSecOps conversation a little more aggressively than you might've seen in the past?  We've been talking about that for some time now, but, you know, organizations are running into a range of technical and cultural issues to try to make all that work.  But, you know, does this become the place where we actually kind of, where that proverbial rubber meets the road, right?  Yeah.  I mean, one of the, one of the really nice things about, you know, the Kubernetes world is that Kubernetes provides a uniform interface for doing things like scanning for vulnerabilities and things like that, both Kubernetes and containers, right?  So it's a lot easier to automate some of this process, to get scanning set up, you know, in a way that's consistent.  You see, you know, so the same open source tools getting deployed across organizations.  So it's becoming easier to kind of push that feedback in a uniform way back to developers.  So I think it is helping things quite a bit.  Neil, we got a question from a participant.  I'm going to kick it back to you.  It says, you know, what advice can you give for setting up a secure supply chain to pull basic images to protect the organization's software development from using insecure, vulnerable, third party container basic images?  Which I think would account for 80% of them.  Yeah, Alex, that's a great question.  And sorry, it was Alex who asked the question.  I was looking at it as well.  But Mike, that is also a great question.  You know, I think there are a couple of basic things, right?  The first one is it starts with policy.  It starts with security architects, security leadership, writing this down and saying, here's how we're going to manage this.  Here's what we're going to use.  We're going to use only Alpine based images, or we're going to use only RHEL based images or whatever that is.  Start there.  Figure out, OK, that gets you so far because you're going to want, you know, a standard Python image or a standard Golang image or a standard, you know, whatever you're whatever you're building on top of.  Make a decision.  Are you going to build those things internally and take on the test burden of doing that?  Or are you going to use something externally?  And if so, identify how you can trust that external image.  And so now we've got policy down to a place I can start putting technical controls in, right?  I can start saying, if I'm scanning, say, my Docker files before I ever build, I can say the from, you know, the from directive has to be in this list.  It has to come from this registry, this repo, so that I can't even build something that comes from an image outside of the images I'm deciding on.  You know, I can I can potentially, as I sort of scale up in complexity, I may be using something like Artifactory where I can start creating essentially a proxy for even pulling images and putting a control in place.  Even if somebody builds something outside of outside of where I can enforce my checks at the edge of the network, I can say, hey, you can't pull that.  It's not in our list of approved approved bases.  And then I think, you know, once again, as you write that policy out, it's a matter of figuring out what the right checks are, where you build them into that pipeline to find those things.  All right, Nung, do you want to add to that?  Because you're having a little sidebar conversation here about the Codalorian or the Mandalorian, I think, or some variation of that.  So are patterns starting to emerge that we can think about here in terms of how to institute DevSecOps in a way that people will not resist?  Yeah, working off of Neil's discussion, putting in those tools to do to scan your art, you mentioned Artifactory.  And that's exactly what I was thinking, is do you have all your images pulled in to a place that you can control and you can install those image scanning tools, code scanning tools?  And someone participating in 706 asked it, what is the best way to integrate security in a Kubernetes pipeline?  And you think about your code pipeline to get into those clusters.  And that's exactly one way to do that is to have in your build server, all those governance tools that can scan your code.  You have a build pipeline already prearranged, and someone goes through and has a control on that.  It's on a secured server, but your build server is protected.  And the products that it builds, the images, go into a repo that you can control, and then you have something that governs that as well.  And then, of course, the predefined pipeline to ship it to your environments.  And locking down your QA and your staging environments in a similar fashion as your production environment, so that way, when you ship these containers, they're going to behave in the same manner that you want them to in production.  And if you have those same guardrails in QA, you're able to identify them right away so that there are no surprises that perhaps you were trying to do something in your container that is not going to be allowed in the more secure environments.  Robert, what makes it hard to create these perfect development chains and pipelines?  Because, you know, Nung and Neil made it sound real simple, and yet it doesn't seem like many people are able to accomplish that.  So from your perspective, what is it that hangs everybody up?  Yeah, so I would say that the real issue is that you have several different points along the pipeline where you need to integrate.  So at Fairwinds, we like to think of it in three pieces.  One is at the time of CI, so scanning every pull request for the infrastructure as code and what's changing there.  Next would be the time of admission.  So as things are coming into the Kubernetes cluster, being able to check them there and kind of stop them at the door.  That way, if somebody bypasses your CI-CD pipeline, you know, maybe they're trying to edit something directly in the cluster.  You know, maybe it's a break glass situation, and they're trying to like fix something.  You have a chance to say, no, this is insecure, you're trying to run as root, you can stop it at the door.  But then in addition to that, you want to be scanning your live production environment kind of continuously so that, you know, if, say, you roll out a new policy or a new vulnerability gets announced and you've got a container running in production that may be passed in CI, passed in admission, but now this new vulnerability has been announced a day later.  You want to be able to catch that and say, oh, I know I'm running this vulnerability in production.  I need to re-trigger that pipeline and make sure that it rebuilds without that vulnerability and I can stop that.  So the big issue is that you need to be integrating in three different spots.  And it seems like the goal should be that I'm trying to get to some sort of zero trust nirvana.  And yet a lot of people feel like the term zero trust isn't feasible because there's a million dependencies everywhere.  So Neil, what's your sense of, you know, what's real and what's not real about zero trust and especially in an environment where there are more APIs than I can shake a stick at?  Yeah, I mean, I think so.  Zero trust, the term is certainly overused and applied to everything and slapped on like a label.  We could in the security industry and in technology, we could come up with a million examples of that.  All the single panes of glass I've worked with over time, you know, et cetera.  But the concept is very, very solid.  And the concept is just, you know, everything to some extent, I have to think of everything as public.  I have to think of everything as accessible.  And so I have to figure out, I can't just automatically assume because a request is coming from something else inside what we used to call the moat, the castle, right?  I can't just assume that's OK.  I have to figure out at every step of the way, how do I make sure this is a valid request?  This is a valid command.  This is a valid action.  And I think, honestly, as you move into Kubernetes, containers, cloud native, microservices, all of these things, it's the perfect place to do it because you've broken it down into these components now and you can start really setting those boundaries and figuring out where they are and codifying them and building them up.  You know, ultimately, once again, this is, you know, I said earlier, focus on simplicity.  You don't have to solve every one of these things at a time.  It's OK to have 20% trust before you get to 0% trust, right?  But let's knock out, let's knock these things out and let's focus on the philosophy of how we want to approach it rather than on the specific products or on having to accomplish this and crush the whole thing all at once.  Now, what's your thought on this?  Yeah, one more.  Yeah, go ahead.  There's also two ways of understanding, like the term zero trust, right?  Zero trust being absolutely no trust.  Then there's also zero trust where we're addressing zero day, meaning the immediate threat that just showed up, right?  The one that you didn't prepare for or you couldn't think of, but hopefully you did prepare for it because that's what zero trust is, is it's that journey to getting that perfection of absolute, you know, ask question everything, you know, don't trust, but verify all your applications that they are communicating in the way that you designed them to communicate.  They're delivering the packets that you want them to deliver and they're expecting and implementing policies that give these services and these workloads the least amount of privilege in order for them to accomplish their work.  And I think one thing is practicing, you know, assume that you have been breached and then going through drills and understanding, having a runbook for a breach.  What do you do?  Rather than waiting for an actual breach to happen, you know, you've got your data compromised.  What is your first course of action?  Do you know what that is?  Have you practiced it?  And I think, you know, it's a good point.  To me, the real purpose of zero trust is to limit the impact of a compromise.  Zero trust doesn't stop a compromise on the edge of my network, but it reduces the ability of the attacker to move from that initial compromise to what's really interesting.  And so that's why I think of it as a philosophy and not a single thing.  It's how do I start limiting if I compromise any single asset in the environment?  How do I limit the ability of that attacker to make use of that and move further into the environment and get to more interesting things?  And that's a key, like, you've got to be doing that.  I almost never used the term zero day vulnerability because my previous life was as an incident response investigator, and I did 13 years of looking at when things went wrong.  And in that time, there was maybe once that a zero day vulnerability was one of the root causes of it.  People get compromised via unpatched known vulnerabilities, poor configurations, bad decisions,  a thousand times more frequently than they get compromised by something that wasn't previously known.  But once again, those things are trade-offs, right?  Things aren't patched because it's hard to patch or you can't reboot that or you don't have a window or you don't have the right tools or whatever else to configure it.  All of these things, you've got to plan ahead and think, all right, I have these.  I have these vulnerabilities.  I have these misconfigurations.  What do I do to limit the impact of any individual one of them?  And how do I architect with that in mind across everything I'm deploying?  Yeah, a three-month-old vulnerability isn't sexy.  Yeah.  Is it embarrassing to be compromised by a known vulnerability these days?  I mean, to what degree do people feel a certain amount of, I don't know if I want to use the word,  but I will shame about the fact that they got breached by the same SQL injection breach that's been going on for two decades?  Yeah, it probably is embarrassing, but it shouldn't be.  It should be like what Neil just said.  The zero days are the catch word and the scary thing because we're talking about it now,  but three months from now, we're not talking about it anymore.  So did you fix it?  Or you didn't even use that service or that technology that was vulnerable,  and then you're just getting around to using it,  and you're not aware that that CVE was published 30 days, 90 days ago.  Of course, that's where your scanning tools should hopefully pick it up.  Yeah, I just have too many scanning tools,  and they're all sending me alerts that I can't sort through, right?  That's generally part of the issue.  Robert, do we need to walk away as part of the zero trust mindset from this castle and moat mindset?  Because I always thought we had these great moats and castles with high walls,  but the roof was wide open and the bad guys are just throwing rocks over the wall.  So what's your sense of do we need a better metaphor to think about security going forward?  Because I think maybe part of our issue is we've kind of just wedded ourselves to  an obsolete construct.  Yeah, no, I absolutely think so.  Neil pointed out, just because something's past your moat doesn't mean you can trust it, right?  A lot of what we talk about when we talk about Kubernetes security,  it's about limiting the blast radius.  It's about assuming that somebody got into a vulnerable container  and figuring out how do we lock them into that container  so they can't spread throughout the cluster, right?  I wish I could think of a good metaphor off the top of my head,  I think limiting the blast radius is the best I can come up with.  I guess micro-segmentation wherever we can find it.  Hey, like it or not, but the compliance people have played a large role in  at least incentivizing us all to do some level of security.  And we can argue it's checkbox security, but it's something and usually better than nothing.  But I guess, do you think that Neil, the compliance people are starting  to figure out this whole Kubernetes thing  and they're going to start asking some tougher questions soon?  And maybe even the insurance guys will show up behind them saying,  hey, this isn't going to suffice and we'll get better.  Yeah, I think we've seen great movement.  First of all, on the platform, right?  We had CIS Kubernetes and I'm trying to think, I don't know,  2019-ish, that was really difficult because we had EKS, GKE,  OpenShift, all these other things coming.  What's happened in the intervening years is we've seen CIS GKE, CIS EKS,  CIS for all of these platforms getting much, much more specific  so that we have good benchmarks for the specific Kubernetes platform  that I'm running on, good compliance.  So that, I mentioned early at the start, I said, if I deploy say EKS,  I'm in good shape unless I go and do something stupid.  CIS gives me a set of guardrails for that  so that I can hopefully in an automated way,  hopefully I have tooling that goes and does this and returns back and says,  oh, you've drifted out of desired compliance, you're not doing this and this.  On top of that, I think a lot of the more specific sort of frameworks  are now focused on some of the application security pieces.  The second category, if you will, that I talked about,  about how do I manage securing and deploying this thing  and am I doing that appropriately?  So yeah, I think compliance sometimes is a checkbox,  but I think if you're doing it right, if you're doing it effectively,  compliance is a canary that tells you if there's a gas leak in your coal mine,  so to speak, and that was a really tortured metaphor.  But it is going to show me,  hopefully I'm doing things to secure the environment and the applications properly  and compliance standards and benchmarks are going to show me when I get out of that  versus I'm doing things to meet the compliance benchmarks  and not caring about the actual security.  Robert, we hear a lot about compliance as code.  Can we get to that?  Is that the guardrail that you were talking about?  But it'll just be kind of part of the overall system.  Yeah, I mean, so one of the things that we've actually done at Fairwinds  as part of our offering around Kubernetes  is mapping Kubernetes security controls back to compliance standards like SOC2 and HIPAA.  And it's definitely a lot of it is centered around,  you know, do you have these kinds of guardrails in place  to make sure that your developers aren't running containers as root,  to make sure that you're scanning every container image  that goes into your production environment.  So there is a lot of like compliance as code, as you said,  it comes down to a lot of policy as code.  Actually, one of the checks we make sure is that you're using a policy as code setup  so that, you know, all your policy changes are being checked in,  that they're being tracked, things like that.  So I think it is very important to have a lot of this encoded in a Git repository.  All right, folks, now we're going to play Mike's favorite game.  It's called King for a Day.  Nung, you have been made king for the day  for the entire Kubernetes Technical Oversight Committee.  Everybody has to bend to your will immediately.  What is that one security thing that you would like to see fixed  that would be at the top of your list that would be like,  guys, let's make this our focal point and fix this thing now?  Ah, I struggled with this one.  I guess an auto generation of security policies.  Maybe implement it, go the reverse way,  deny all and then make your developers start to open,  deliberately open ports and communications between workloads.  That's pretty good. I like that.  Neil, what are you thinking?  Well, so that was one on my list.  So the one I'm going to throw out is partially fixed at this point.  It's partially done, but I think uptake has been slow.  I want to see image signing happening across the board as the default for everybody.  Because there are so many, when we talk about supply chain  and sort of all of that stuff, there's so many benefits we can mine there  that I think we're just starting to get to.  It's image signing has been problematic in Docker images for a long time.  I think co-sign is a really strong solution.  People are starting to embrace it.  I want to see that go to 100%.  I want to see that to be the default.  And you have to break glass to not sign an image.  Awesome. Robert, what do you think?  I would love to see a real clear first class distinction  between application namespaces and infrastructure namespaces.  There are a lot of tools that have to run in Kubernetes  that A, have a reduced attack surface  because they're not exposing ingresses to the internet.  And they need a higher degree of permissions to do their jobs,  things like ingress controllers and certificate managers,  money to edit resources and other namespaces, things like that.  So kind of segregating those from your application namespaces,  which shouldn't need very much permissions within the cluster  and which have a higher attack surface  because they're accepting traffic from the internet.  I think having that distinction in Kubernetes would be really helpful.  All right.  Noam, you kind of touched on this,  but I'm going to throw it out here in a little more far-fetched kind of way.  But you cannot walk down the street these days  without somebody talking about generative AI,  this, that, and the other and chat GPT.  So I guess my question to you guys is,  do you think that we might be able to use these platforms  to first automate the writing of the controls  because we can just use the AI to read the regulation  and generate the control?  And then maybe do some of the things that Noam was talking about  in terms of enforcing those policies.  Robert, what do you think?  Yeah.  So I actually, you know, I'm a former data scientist.  I'm, my degree is in AI.  So I'm all over this stuff.  You're a recovering data scientist.  Exactly. Yeah.  So we, one of the policy languages we work with is Rego,  which is super powerful, but also like really hard to write.  It confuses a lot of people.  So we've actually done some experimenting with chat GPT,  getting it to generate Rego code.  And it does a really good job.  If you say, I want to require label X on every deployment,  but only in these namespaces,  it will write you the Rego policy to do it.  So it is actually, it's, I think, potentially a very powerful tool.  Obviously, you know, it makes bugs.  You have to second check its work.  You have to make sure you're viewing that code,  but it does a surprisingly good job.  Neil, what do you think?  I feel like you're throwing me a softball  because in Orca, we released a chat or a GPT-3 driven feature recently  to help people author remediations for alerts.  So it's quite literally that, okay, I've got an alert.  I don't know how to fix it.  Give me some ideas on how to fix this in the CLI or in Terraform  or sort of in however I want to do that.  Yeah. And I think it's incredibly powerful.  That's the sort of tightly constrained problem  that I think generative AI is really good at solving today.  It's not perfect.  I still have to, like, look at it and rationalize it  and make sure it hasn't decided to, you know,  FDisk and format every machine in my environment.  But it does a reasonably good job of, you know,  hey, I need to tighten the permissions on this S3 bucket.  Okay, here's how you might do that in Terraform.  Or here's how you might do that in the CLI.  So yeah, I'm really bullish on the possibility  of what we can build on top of it.  All right. Somebody wants a hoodie like Robert's there.  I don't know if we can figure out how to do that,  but there's a thought.  Now, do you think that AI will save us from ourselves?  Because part of these issues are things that we've just,  as humans, made too complex.  So maybe the machines need to save us.  Yeah. It could help us, definitely.  There's just too much.  There's too much to keep track of.  And if you break all these things down  into little parts, yes, you can identify them.  You can go back to when, you know,  the community addressed the particular problem  and wrote some kind of code around it  or came up with a process around that.  But then it just gets put on the pile  of everything that we're supposed to know  as a developer or as a DevOps.  And yeah, now we have DevSecOps.  And, you know, just keep adding.  Now we'll have to have the DevSecAI or MLOps  because we're going to start generating  machine learning patterns  and we'll start throwing in scenarios  because part of using chat GPT  is knowing how to ask it the questions you want answered.  Not just, oh, it's here,  and just plug in a few words and go.  If you know how to ask it the right questions,  you're going to get a pretty good model out of it  that's going to be that robust  or that scaffold for your next security policy generator.  All right, Robert, last one to you.  Besides the fact that you are now  dictating IT fashion out there  and people are going shopping with your hoodie,  what's your sense of,  are we optimistic about security these days?  And for that matter,  do I need to know as much as I know today  or, you know, by this time next year,  is it going to be such a high level of automation  and abstractions that I should just focus on the end result  rather than, you know,  the test tubes that were used to make the television?  Yeah, yeah, that's a great question.  Yeah, I think we're seeing things  get more and more automated.  Like I said before, you know,  the fact that we have increasingly  a like well-defined API  for doing the scanning and things like that,  container scanning, you know,  we've got Terraform scanning.  You can look through the cloud provider's API.  So it's much easier to deploy the same tools  across organizations to understand  each of those organizations' security profile.  So you are seeing a lot more and more automation.  And I think automating this as much as possible.  The big thing I think we still have to do  is automated remediation,  which I think some of the AI stuff  comes along that line.  A lot of different companies,  including Fairwinds are working along those lines.  So once we get to automated remediation,  I think we'll be in a much better place security-wise.  All right, things are better than they look.  Gentlemen, thank you for being on the show  and sharing your knowledge and expertise.  I hope everybody got a lot out of it.  And with that, I'm going to hand it back to Cody.  Thank you, Mike.  And also thank you to Robert, Neil,  and Nung for joining us today.  So I'd like to remind our audience  that this session was recorded.  You will be receiving an email  with a link to access this recording on demand.  Or of course you can find it  living on the Container Journal website  at containerjournal.com slash webinars.  The four winners of our $25 Amazon gift card drawing  are Fabrice K., Balaji M., Vivian X., and Roshan K.  So to our four winners, congratulations.  Keep an eye on your inbox for that email.  You should be receiving it in about 48 hours.  But if you don't happen to see that email,  do check your spam folder in case it gets filtered out.  And so to everyone who has joined us for the last hour,  thank you for being here.  We really appreciate your time.  There will be a survey that pops up as soon as we close out.  So feel free to fill that out for us  and let us know what you thought about our program  or maybe what you'd like to see on an upcoming program.  But either way, we would like to see everyone  at a future TechStrong learning experience.  Have a great rest of your day.  And to our entire panel, thank you all once more. 